import streamlit as st
import pandas as pd
import requests
import urllib3
from urllib.parse import quote
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import json
import os
import re
import time
import yfinance as yf

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==========================================
# 0. í˜ì´ì§€ ì„¤ì • ë° ìŠ¤íƒ€ì¼
# ==========================================
st.set_page_config(layout="wide", page_title="Semi-Insight Hub", page_icon="ğŸ’ ")

st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@300;400;500;600;700&display=swap');
        html, body, .stApp { font-family: 'Pretendard', sans-serif; background-color: #F8FAFC; color: #1E293B; }
        
        /* ë¦¬í¬íŠ¸ ìŠ¤íƒ€ì¼ */
        .report-box { background-color: #FFFFFF; padding: 40px; border-radius: 12px; border: 1px solid #E2E8F0; box-shadow: 0 4px 15px rgba(0,0,0,0.05); margin-bottom: 30px; line-height: 1.8; color: #334155; }
        .history-header { font-size: 1.2em; font-weight: 700; color: #475569; margin-top: 50px; margin-bottom: 20px; border-left: 5px solid #3B82F6; padding-left: 10px; }
        
        /* ë‰´ìŠ¤ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
        .news-card { background: white; padding: 15px; border-radius: 10px; border: 1px solid #E2E8F0; margin-bottom: 10px; }
        .news-title { font-size: 16px !important; font-weight: 700 !important; color: #111827 !important; text-decoration: none; display: block; margin-bottom: 6px; }
        .news-title:hover { color: #2563EB !important; text-decoration: underline; }
        .news-meta { font-size: 12px !important; color: #94A3B8 !important; }

        /* ì‚¬ì´ë“œë°” ì£¼ì‹ í°íŠ¸ ê°•ì œ ê³ ì • */
        section[data-testid="stSidebar"] div[data-testid="stMetricValue"] { font-size: 18px !important; font-weight: 600 !important; }
        section[data-testid="stSidebar"] div[data-testid="stMetricDelta"] { font-size: 12px !important; }
        section[data-testid="stSidebar"] div[data-testid="stMetricLabel"] { font-size: 12px !important; color: #64748B !important; }
        .stock-header { font-size: 13px; font-weight: 700; color: #475569; margin-top: 15px; margin-bottom: 5px; border-bottom: 1px solid #E2E8F0; padding-bottom: 4px; }
    </style>
""", unsafe_allow_html=True)

# ê¸°ë³¸ê°’ ì„¤ì •
FALLBACK_API_KEY = "AIzaSyCBSqIQBIYQbWtfQAxZ7D5mwCKFx-7VDJo"
CATEGORIES = ["Daily Report", "ê¸°ì—…ì •ë³´", "ë°˜ë„ì²´ ì •ë³´", "Photoresist", "Wet chemical", "CMP Slurry", "Process Gas", "Wafer", "Package"]

# [ìš”ì²­í•˜ì‹  ì¢…ëª© ì›ë³µ]
STOCK_CATEGORIES = {
    "ğŸ­ Chipmakers": {
        "Samsung": "005930.KS", "SK Hynix": "000660.KS", "Micron": "MU",
        "TSMC": "TSM", "Intel": "INTC", "SMIC": "0981.HK"
    },
    "ğŸ§  Fabless": {
        "Nvidia": "NVDA", "Broadcom": "AVGO", "Qnity (Q)": "Q" 
    },
    "âš™ï¸ Equipment": {
        "ASML": "ASML", "AMAT": "AMAT", "Lam Res": "LRCX", 
        "TEL": "8035.T", "KLA": "KLAC", "Hanmi": "042700.KS", "Jusung": "036930.KS"
    },
    "ğŸ§ª Materials": {
        "Shin-Etsu": "4063.T", "Sumitomo": "4005.T", "TOK": "4186.T", 
        "Nissan Chem": "4021.T", "Merck": "MRK.DE", "Air Liquide": "AI.PA", 
        "Linde": "LIN", "Soulbrain": "357780.KS", "Dongjin": "005290.KS", 
        "ENF": "102710.KS", "Ycchem": "232140.KS"
    },
    "ğŸ”‹ Others": {
        "Samsung SDI": "006400.KS"
    }
}

# ==========================================
# 1. ë°ì´í„° ê´€ë¦¬ (í‚¤ì›Œë“œ, íˆìŠ¤í† ë¦¬, ì£¼ì‹)
# ==========================================
KEYWORD_FILE = 'keywords.json'
HISTORY_FILE = 'daily_history.json'

@st.cache_data(ttl=600)
def get_stock_prices_grouped():
    all_tickers = []
    for cat in STOCK_CATEGORIES.values(): all_tickers.extend(cat.values())
    ticker_str = " ".join(all_tickers)
    result_map = {}
    try:
        stocks = yf.Tickers(ticker_str)
        for symbol in all_tickers:
            try:
                hist = stocks.tickers[symbol].history(period="5d")
                if len(hist) >= 2:
                    current = hist['Close'].iloc[-1]
                    prev = hist['Close'].iloc[-2]
                    change = current - prev
                    pct = (change / prev) * 100
                    cur_sym = "â‚©" if ".KS" in symbol else ("Â¥" if ".T" in symbol else ("HK$" if ".HK" in symbol else ("â‚¬" if ".DE" in symbol or ".PA" in symbol else "$")))
                    fmt_price = f"{cur_sym}{current:,.0f}" if cur_sym in ["â‚©", "Â¥"] else f"{cur_sym}{current:,.2f}"
                    result_map[symbol] = {"Price": fmt_price, "Delta": f"{change:,.2f} ({pct:+.2f}%)"}
            except: pass
    except: pass
    return result_map

def load_keywords():
    data = {cat: [] for cat in CATEGORIES}
    if os.path.exists(KEYWORD_FILE):
        try:
            with open(KEYWORD_FILE, 'r', encoding='utf-8') as f:
                loaded = json.load(f)
            for k, v in loaded.items():
                if k in data: data[k] = v
        except: pass
    if not data.get("Daily Report"): 
        data["Daily Report"] = ["ë°˜ë„ì²´", "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤"] 
    return data

def save_keywords(data):
    try:
        with open(KEYWORD_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except: pass

def load_daily_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: return []
    return []

def save_daily_history(new_report_data):
    history = load_daily_history()
    # ë‚ ì§œ ì¤‘ë³µ ì‹œ ë®ì–´ì“°ê¸° (í•­ìƒ ìµœì‹  ë‚ ì§œê°€ ë§¨ ìœ„ë¡œ ì˜¤ë„ë¡)
    history = [h for h in history if h['date'] != new_report_data['date']]
    history.insert(0, new_report_data)
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=4)
    except: pass

# ==========================================
# 2. [ì„±ê³µí•œ ë¡œì§] AI ëª¨ë¸ ìë™ íƒìƒ‰ ë° ìƒì„±
# ==========================================
def get_available_models(api_key):
    """í˜„ì¬ API Keyë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ"""
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    try:
        res = requests.get(url, timeout=10)
        if res.status_code == 200:
            data = res.json()
            return [m['name'].replace("models/", "") for m in data.get('models', []) if 'generateContent' in m.get('supportedGenerationMethods', [])]
    except: pass
    return []

def generate_report_with_auto_model(api_key, news_data):
    """ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©° 429/404 íšŒí”¼"""
    models = get_available_models(api_key)
    
    # ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª¨ë¸ì…‹ (ì„±ê³µ í™•ë¥  ë†’ì€ ìˆœ)
    if not models:
        models = ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"]
    
    prompt = f"""
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ë°˜ë„ì²´ ì‚°ì—… ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    ì•„ë˜ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ë“¤ì„ ì¢…í•©í•˜ì—¬ **[ì¼ì¼ ë°˜ë„ì²´ ì‚°ì—… ë¸Œë¦¬í•‘]**ì„ ì‘ì„±í•˜ì„¸ìš”.
    
    [ë‰´ìŠ¤ ë°ì´í„°]
    {chr(10).join(news_data)}
    
    [ì‘ì„± ì–‘ì‹ (Markdown)]
    ## ğŸ“Š Executive Summary
    (ì˜¤ëŠ˜ì˜ í•µì‹¬ íë¦„ì„ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½)
    
    ## ğŸš¨ Key Headlines
    (ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ 3ê°€ì§€ ì„ ì • ë° ì‹¬ì¸µ ë¶„ì„)
    
    ## ğŸ“‰ Market & Supply Chain Insight
    (ê¸°ì—… ë™í–¥, ì†Œë¶€ì¥ ì´ìŠˆ, í–¥í›„ ì‹œì¥ ì „ë§)
    """
    
    headers = {'Content-Type': 'application/json'}
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
        ]
    }

    for model in models:
        if "vision" in model: continue # í…ìŠ¤íŠ¸ ì „ìš©
        
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
        try:
            response = requests.post(url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 200:
                res_json = response.json()
                if 'candidates' in res_json and res_json['candidates']:
                    return True, res_json['candidates'][0]['content']['parts'][0]['text']
            elif response.status_code == 429:
                time.sleep(1) 
                continue
        except: continue
            
    return False, "AI ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ì„œë²„ ê³¼ë¶€í•˜ ë˜ëŠ” ì‚¬ìš©ëŸ‰ ì´ˆê³¼)"

# ==========================================
# 3. ë‰´ìŠ¤ í¬ë¡¤ë§
# ==========================================
def fetch_news(keywords, days=1, limit=15):
    all_items = []
    
    for kw in keywords:
        url = f"https://news.google.com/rss/search?q={quote(kw)}+when:{days}d&hl=ko&gl=KR&ceid=KR:ko"
        try:
            res = requests.get(url, timeout=5, verify=False)
            soup = BeautifulSoup(res.content, 'xml')
            items = soup.find_all('item')
            for item in items:
                all_items.append({
                    'Title': item.title.text,
                    'Link': item.link.text,
                    'Date': item.pubDate.text,
                    'Source': item.source.text if item.source else "Google News"
                })
        except: pass
        time.sleep(0.1)
        
    df = pd.DataFrame(all_items)
    if not df.empty:
        df = df.drop_duplicates(subset=['Title'])
        return df.head(limit).to_dict('records')
    return []

# ==========================================
# 4. ë©”ì¸ ì•± UI
# ==========================================
if 'keywords' not in st.session_state: st.session_state.keywords = load_keywords()

# [ì‚¬ì´ë“œë°”]
with st.sidebar:
    st.header("Semi-Insight")
    st.divider()
    selected_category = st.radio("ì¹´í…Œê³ ë¦¬", CATEGORIES, index=0, label_visibility="collapsed")
    st.divider()
    
    with st.expander("ğŸ” API Key"):
        user_key = st.text_input("Key", type="password")
        if user_key: api_key = user_key
        elif "GEMINI_API_KEY" in st.secrets: api_key = st.secrets["GEMINI_API_KEY"]
        else: api_key = FALLBACK_API_KEY
    
    st.markdown("---")
    # [ì£¼ì‹ ì •ë³´ í‘œì‹œ]
    with st.expander("ğŸ“‰ Global Stock", expanded=True):
        stock_data = get_stock_prices_grouped()
        if stock_data:
            for cat, items in STOCK_CATEGORIES.items():
                st.markdown(f"<div class='stock-header'>{cat}</div>", unsafe_allow_html=True)
                for name, symbol in items.items():
                    info = stock_data.get(symbol)
                    if info:
                        c1, c2 = st.columns([1, 1.3])
                        c1.caption(f"**{name}**")
                        c2.metric("", info['Price'], info['Delta'], label_visibility="collapsed")
                        st.markdown("<hr style='margin: 2px 0; border-top: 1px dashed #f1f5f9;'>", unsafe_allow_html=True)

# [ë©”ì¸ í™”ë©´]
c_head, c_info = st.columns([3, 1])
with c_head: st.title(selected_category)

# ----------------------------------
# [Mode 1] Daily Report (06ì‹œ ê¸°ì¤€)
# ----------------------------------
if selected_category == "Daily Report":
    # ì‹œê°„ ê³„ì‚° (KST ê¸°ì¤€)
    now_kst = datetime.utcnow() + timedelta(hours=9)
    # 06ì‹œ ì´ì „ì´ë©´ ì–´ì œ ë‚ ì§œ, 06ì‹œ ì´í›„ë©´ ì˜¤ëŠ˜ ë‚ ì§œ
    if now_kst.hour < 6:
        target_date = (now_kst - timedelta(days=1)).date()
    else:
        target_date = now_kst.date()
    target_date_str = target_date.strftime('%Y-%m-%d')
    
    with c_info:
        st.markdown(f"<div style='text-align:right; color:#888;'>Target Date<br><b>{target_date}</b></div>", unsafe_allow_html=True)

    # 1. í‚¤ì›Œë“œ ì„¤ì •
    with st.container(border=True):
        c1, c2 = st.columns([3, 1])
        new_kw = c1.text_input("ìˆ˜ì§‘ í‚¤ì›Œë“œ ì¶”ê°€", placeholder="ì˜ˆ: HBM, íŒ¨í‚¤ì§•", label_visibility="collapsed")
        if c2.button("ì¶”ê°€", use_container_width=True):
            if new_kw and new_kw not in st.session_state.keywords["Daily Report"]:
                st.session_state.keywords["Daily Report"].append(new_kw)
                save_keywords(st.session_state.keywords)
                st.rerun()
        
        daily_kws = st.session_state.keywords["Daily Report"]
        if daily_kws:
            st.write("")
            cols = st.columns(len(daily_kws) if len(daily_kws) < 8 else 8)
            for i, kw in enumerate(daily_kws):
                if cols[i % 8].button(f"{kw} Ã—", key=f"del_{kw}"):
                    st.session_state.keywords["Daily Report"].remove(kw)
                    save_keywords(st.session_state.keywords)
                    st.rerun()
    
    # 2. ë¦¬í¬íŠ¸ ê´€ë¦¬
    history = load_daily_history()
    today_report = next((h for h in history if h['date'] == target_date_str), None)
    
    # ë¦¬í¬íŠ¸ê°€ ì—†ìœ¼ë©´ ìƒì„± ë²„íŠ¼ í‘œì‹œ
    if not today_report:
        st.info(f"ğŸ“¢ {target_date} ë¦¬í¬íŠ¸ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if st.button("ğŸš€ ê¸ˆì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘", type="primary"):
            status_box = st.status("ğŸš€ ë¦¬í¬íŠ¸ ìƒì„± í”„ë¡œì„¸ìŠ¤...", expanded=True)
            
            # ìˆ˜ì§‘
            status_box.write(f"ğŸ“¡ '{', '.join(daily_kws)}' ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
            news_items = fetch_news(daily_kws, days=1) # 1ì¼ì¹˜ (06ì‹œ ê¸°ì¤€ì´ë¯€ë¡œ ëŒ€ëµ ë§ìŒ)
            
            if not news_items:
                status_box.update(label="âŒ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.", state="error")
            else:
                # ë¶„ì„
                status_box.write(f"ğŸ§  AI ë¶„ì„ ë° ìš”ì•½ ì¤‘... (ê¸°ì‚¬ {len(news_items)}ê±´)")
                news_texts = [f"- {item['Title']}" for item in news_items]
                success, result = generate_report_with_auto_model(api_key, news_texts)
                
                if success:
                    save_data = {'date': target_date_str, 'report': result, 'articles': news_items}
                    save_daily_history(save_data)
                    status_box.update(label="ğŸ‰ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!", state="complete")
                    st.rerun()
                else:
                    status_box.update(label="âš ï¸ AI ë¶„ì„ ì‹¤íŒ¨", state="error")
                    st.error(result)
    
    # ì´ë¯¸ ìƒì„±ëœ ê²½ìš° ì¬ìƒì„± ì˜µì…˜
    else:
        st.success(f"âœ… {target_date} ë¦¬í¬íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        if st.button("ğŸ”„ ë¦¬í¬íŠ¸ ë‹¤ì‹œ ë§Œë“¤ê¸° (ë®ì–´ì“°ê¸°)"):
            status_box = st.status("ğŸš€ ë¦¬í¬íŠ¸ ì¬ìƒì„± ì¤‘...", expanded=True)
            news_items = fetch_news(daily_kws)
            if news_items:
                news_texts = [f"- {item['Title']}" for item in news_items]
                success, result = generate_report_with_auto_model(api_key, news_texts)
                if success:
                    save_data = {'date': target_date_str, 'report': result, 'articles': news_items}
                    save_daily_history(save_data)
                    status_box.update(label="ğŸ‰ ì¬ìƒì„± ì™„ë£Œ!", state="complete")
                    st.rerun()

    # 3. íˆìŠ¤í† ë¦¬ ì¶œë ¥ (ëˆ„ì )
    if history:
        for entry in history:
            st.divider()
            st.markdown(f"<div class='history-header'>ğŸ“… {entry['date']} Daily Report</div>", unsafe_allow_html=True)
            st.markdown(f"<div class='report-box'>{entry['report']}</div>", unsafe_allow_html=True)
            
            # [ìš”ì²­ì‚¬í•­] Reference Links
            with st.expander(f"ğŸ”— Reference Articles ({len(entry.get('articles', []))}ê±´)"):
                for i, item in enumerate(entry.get('articles', [])):
                    st.markdown(f"**{i+1}. [{item['Title']}]({item['Link']})** <span style='color:#888; font-size:0.8em'> | {item['Source']}</span>", unsafe_allow_html=True)

# ----------------------------------
# [Mode 2] General Category (ìˆ˜ë™)
# ----------------------------------
else:
    with st.container(border=True):
        c1, c2, c3 = st.columns([2, 1, 1])
        new_kw = c1.text_input("í‚¤ì›Œë“œ", label_visibility="collapsed")
        if c2.button("ì¶”ê°€", use_container_width=True):
            if new_kw:
                st.session_state.keywords[selected_category].append(new_kw)
                save_keywords(st.session_state.keywords)
                st.rerun()
        if c3.button("ì‹¤í–‰", type="primary", use_container_width=True):
            kws = st.session_state.keywords[selected_category]
            if kws:
                news = fetch_news(kws, limit=20)
                st.session_state.news_data[selected_category] = news
                st.rerun()

        curr_kws = st.session_state.keywords[selected_category]
        if curr_kws:
            st.write("")
            cols = st.columns(8)
            for i, kw in enumerate(curr_kws):
                if cols[i%8].button(f"{kw} Ã—", key=f"gdel_{kw}"):
                    st.session_state.keywords[selected_category].remove(kw)
                    save_keywords(st.session_state.keywords)
                    st.rerun()

    data = st.session_state.news_data.get(selected_category, [])
    if data:
        st.write(f"ì´ {len(data)}ê±´ ìˆ˜ì§‘ë¨")
        for item in data:
            st.markdown(f"""
            <div class="news-card">
                <div class="news-meta">{item['Source']} | {item['Date']}</div>
                <a href="{item['Link']}" target="_blank" class="news-title">{item['Title']}</a>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("ìƒë‹¨ì˜ 'ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")
