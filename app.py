import streamlit as st
import pandas as pd
import requests
import urllib3
from urllib.parse import quote
from bs4 import BeautifulSoup
from datetime import datetime, timedelta, date
import time
import random
import json
import os

# Selenium & Webdriver Manager
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service

# ==========================================
# 0. ì„¤ì • ë° CSS ìŠ¤íƒ€ì¼ë§ (ê³µë°± ìµœì†Œí™”, í°íŠ¸ ì¡°ì •)
# ==========================================
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

st.set_page_config(layout="wide", page_title="Semiconductor News Crawler")

# [CSS ìˆ˜ì •] ìƒë‹¨ ê³µë°± ìµœì†Œí™” ë° í°íŠ¸ ì‚¬ì´ì¦ˆ ì¡°ì ˆ
st.markdown("""
    <style>
        /* ë©”ì¸ ì»¨í…Œì´ë„ˆ ìƒë‹¨ íŒ¨ë”© ì¤„ì´ê¸° */
        .block-container {
            padding-top: 1rem !important;
            padding-bottom: 1rem !important;
        }
        /* ì „ì²´ í°íŠ¸ ì‚¬ì´ì¦ˆ ì•½ê°„ ì¶•ì†Œ (80%) */
        html, body, [class*="css"] {
            font-size: 0.95rem;
        }
        /* ì œëª©(H1) í¬ê¸° ì¡°ì ˆ */
        h1 {
            font-size: 1.8rem !important;
            margin-bottom: 0.5rem !important;
        }
        /* ë¶€ì œëª©(H3) í¬ê¸° ì¡°ì ˆ */
        h3 {
            font-size: 1.3rem !important;
            padding-top: 0.5rem !important;
        }
        /* Made by LSH í‘¸í„° ìŠ¤íƒ€ì¼ (ì‚¬ì´ë“œë°” í•˜ë‹¨ ê³ ì •) */
        .sidebar-footer {
            position: fixed;
            bottom: 10px;
            left: 20px;
            font-size: 10px;
            color: #888888;
            z-index: 999;
        }
    </style>
""", unsafe_allow_html=True)

CATEGORIES = [
    "ë°˜ë„ì²´ ì •ë³´", "Photoresist", "Wet chemical", "CMP Slurry", 
    "Process Gas", "Precursor", "Metal target", "Wafer"
]

# ==========================================
# 1. í‚¤ì›Œë“œ ì €ì¥/ë¡œë“œ í•¨ìˆ˜ (JSON íŒŒì¼ í™œìš©)
# ==========================================
KEYWORD_FILE = 'keywords.json'

def load_keywords():
    """íŒŒì¼ì—ì„œ í‚¤ì›Œë“œë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ë°˜í™˜"""
    if os.path.exists(KEYWORD_FILE):
        try:
            with open(KEYWORD_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass # íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
    
    # ê¸°ë³¸ í‚¤ì›Œë“œ (ì´ˆê¸°ê°’)
    return {cat: [] for cat in CATEGORIES}

def save_keywords(keywords_dict):
    """í‚¤ì›Œë“œ ë³€ê²½ ì‹œ íŒŒì¼ì— ì €ì¥"""
    try:
        with open(KEYWORD_FILE, 'w', encoding='utf-8') as f:
            json.dump(keywords_dict, f, ensure_ascii=False, indent=4)
    except Exception as e:
        st.error(f"í‚¤ì›Œë“œ ì €ì¥ ì‹¤íŒ¨: {e}")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì €ì¥ëœ í‚¤ì›Œë“œ ë¶ˆëŸ¬ì˜¤ê¸°)
if 'keywords' not in st.session_state:
    st.session_state.keywords = load_keywords()

if 'news_data' not in st.session_state:
    st.session_state.news_data = {cat: [] for cat in CATEGORIES}

if 'last_update' not in st.session_state:
    st.session_state.last_update = None

# ==========================================
# 2. í¬ë¡¤ë§ ì—”ì§„
# ==========================================
def get_headers():
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36'
    ]
    return {'User-Agent': random.choice(user_agents)}

def parse_date(date_str):
    try:
        return pd.to_datetime(date_str).to_pydatetime()
    except:
        return datetime.now()

def crawl_ijiwei(keyword, debug_mode=False):
    results = []
    base_url = f"https://www.ijiwei.com/search?keyword={quote(keyword)}"
    
    if debug_mode:
        st.markdown(f"**[Ijiwei]** ì ‘ì† ì‹œë„: `{base_url}`")

    chrome_options = Options()
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36")
    
    driver = None
    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.get(base_url)
        
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "search-item"))
            )
        except:
            time.sleep(2)
        
        if debug_mode:
            st.image(driver.get_screenshot_as_png(), caption=f"Ijiwei í™”ë©´ ìº¡ì²˜: {keyword}", width=400)
            
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        articles = soup.find_all('div', class_='search-item')
        if not articles:
             articles = soup.find_all('li', class_='news-item')
        
        if debug_mode:
            st.write(f"ğŸ‘‰ **[Ijiwei]** ë°œê²¬ëœ íƒœê·¸ ìˆ˜: {len(articles)}ê°œ")

        for item in articles:
            try:
                title_tag = item.find('a', class_='title')
                date_tag = item.find('span', class_='date')
                
                if title_tag:
                    title = title_tag.get_text(strip=True)
                    link = title_tag['href']
                    if not link.startswith('http'):
                        link = "https://www.ijiwei.com" + link
                    date_str = date_tag.get_text(strip=True) if date_tag else str(datetime.now().date())
                    
                    results.append({
                        'Title': title,
                        'Source': 'Ijiwei (China)',
                        'Date': parse_date(date_str),
                        'Link': link,
                        'Keyword': keyword
                    })
            except Exception:
                continue
    except Exception as e:
        if debug_mode:
            st.error(f"[Ijiwei Error] {e}")
        print(f"Ijiwei Selenium error: {e}")
    finally:
        if driver:
            driver.quit()
    return results

def crawl_google_news(keyword, country_code, language, debug_mode=False):
    results = []
    base_url = f"https://news.google.com/rss/search?q={quote(keyword)}&hl={language}&gl={country_code}&ceid={country_code}:{language}"
    
    if debug_mode:
        st.write(f"ğŸ“¡ **[Google-{country_code}]** ìš”ì²­ URL: `{base_url}`")

    try:
        response = requests.get(base_url, headers=get_headers(), timeout=10, verify=False)
        
        soup = BeautifulSoup(response.content, 'xml')
        items = soup.find_all('item')
        
        if debug_mode:
            st.write(f"ğŸ‘‰ ë°œê²¬ëœ ê¸°ì‚¬ ìˆ˜: {len(items)}ê°œ")
        
        for item in items:
            title = item.title.text
            link = item.link.text
            pub_date = item.pubDate.text
            source = item.source.text if item.source else "Google News"
            
            results.append({
                'Title': title,
                'Source': f"{source} ({country_code})",
                'Date': parse_date(pub_date),
                'Link': link,
                'Keyword': keyword
            })
    except Exception as e:
        if debug_mode:
            st.error(f"[Google Error] {e}")
    return results

def perform_crawling(category, start_date, end_date, debug_mode):
    keywords = st.session_state.keywords[category]
    collected_data = []
    
    start_dt = datetime.combine(start_date, datetime.min.time())
    end_dt = datetime.combine(end_date, datetime.max.time())
    
    progress_bar = st.progress(0)
    
    if not keywords:
        st.warning("ë“±ë¡ëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    total_steps = len(keywords) * 4
    step = 0
    
    status_text = st.empty()

    for kw in keywords:
        status_text.text(f"ğŸ” '{kw}' ê²€ìƒ‰ ì¤‘... (Ijiwei)")
        collected_data.extend(crawl_ijiwei(kw, debug_mode))
        step += 1; progress_bar.progress(step / total_steps)
        
        status_text.text(f"ğŸ” '{kw}' ê²€ìƒ‰ ì¤‘... (Korea)")
        collected_data.extend(crawl_google_news(kw, 'KR', 'ko', debug_mode))
        step += 1; progress_bar.progress(step / total_steps)
        
        status_text.text(f"ğŸ” '{kw}' ê²€ìƒ‰ ì¤‘... (USA)")
        collected_data.extend(crawl_google_news(kw, 'US', 'en', debug_mode))
        step += 1; progress_bar.progress(step / total_steps)
        
        status_text.text(f"ğŸ” '{kw}' ê²€ìƒ‰ ì¤‘... (Japan)")
        collected_data.extend(crawl_google_news(kw, 'JP', 'ja', debug_mode))
        step += 1; progress_bar.progress(step / total_steps)
        
    progress_bar.empty()
    status_text.empty()
    
    total_found = len(collected_data)
    
    df = pd.DataFrame(collected_data)
    if not df.empty:
        df = df[(df['Date'] >= start_dt) & (df['Date'] <= end_dt)]
        filtered_count = len(df)
        
        if debug_mode:
            st.info(f"ğŸ“Š **í†µê³„ ë¦¬í¬íŠ¸**\n\n- ì „ì²´ ìˆ˜ì§‘ëœ ê¸°ì‚¬: {total_found}ê°œ\n- ë‚ ì§œ í•„í„°({start_date}~{end_date}) í›„: {filtered_count}ê°œ")

        df = df.sort_values(by='Date', ascending=False)
        df = df.head(50)
        st.session_state.news_data[category] = df.to_dict('records')
    else:
        if debug_mode:
            st.warning("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ 0ê±´ì…ë‹ˆë‹¤.")
        st.session_state.news_data[category] = []

# ==========================================
# 3. UI ë ˆì´ì•„ì›ƒ
# ==========================================

with st.sidebar:
    st.header("ğŸ“‚ Categories")
    selected_category = st.radio("í•­ëª©ì„ ì„ íƒí•˜ì„¸ìš”:", CATEGORIES)
    
    st.divider()
    
    st.subheader("ğŸ› ï¸ Debug Tools")
    debug_mode = st.checkbox("ğŸ ë””ë²„ê¹… ëª¨ë“œ í™œì„±í™”", value=False)
    
    st.divider()
    st.info("""
    ğŸ’¡ **ê²€ìƒ‰ íŒ:**
    - `Samsung HBM` (AND)
    - `Samsung OR TSMC` (OR)
    """)
    
    # [ìˆ˜ì •] í•˜ë‹¨ "Made by LSH" ë¬¸êµ¬ ì¶”ê°€
    st.markdown("<div class='sidebar-footer'>Made by LSH</div>", unsafe_allow_html=True)

col_title, col_btn = st.columns([4, 1])
with col_title:
    st.title(f"{selected_category} News")

with col_btn:
    st.write("") 
    update_clicked = st.button("ğŸ”„ Update News", type="primary")

st.divider()

st.subheader("âš™ï¸ Search Settings & Keywords")
col_settings, col_keywords = st.columns([1, 1.5])

with col_settings:
    st.markdown("##### ğŸ“… ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì •")
    period_option = st.radio(
        "ê¸°ê°„ ì„ íƒ",
        ["1ê°œì›”", "3ê°œì›”", "6ê°œì›”", "ê¸°ê°„ì§€ì •"],
        horizontal=True
    )
    
    today = datetime.now().date()
    start_date = today
    end_date = today
    
    if period_option == "1ê°œì›”":
        start_date = today - timedelta(days=30)
    elif period_option == "3ê°œì›”":
        start_date = today - timedelta(days=90)
    elif period_option == "6ê°œì›”":
        start_date = today - timedelta(days=180)
    elif period_option == "ê¸°ê°„ì§€ì •":
        date_range = st.date_input("ì‹œì‘ì¼ - ì¢…ë£Œì¼ ì„ íƒ", (today - timedelta(days=7), today), max_value=today)
        if len(date_range) == 2:
            start_date, end_date = date_range
        else:
            start_date = date_range[0]; end_date = start_date

with col_keywords:
    st.markdown("##### ğŸ”‘ í‚¤ì›Œë“œ ê´€ë¦¬")
    c_input, c_add = st.columns([3, 1])
    with c_input:
        new_keyword = st.text_input("ìƒˆ í‚¤ì›Œë“œ ì…ë ¥", key="new_kw_input")
    with c_add:
        if st.button("ì¶”ê°€", use_container_width=True):
            if new_keyword and new_keyword not in st.session_state.keywords[selected_category]:
                st.session_state.keywords[selected_category].append(new_keyword)
                # [ìˆ˜ì •] í‚¤ì›Œë“œ ì¶”ê°€ ì‹œ íŒŒì¼ ì €ì¥ í˜¸ì¶œ
                save_keywords(st.session_state.keywords)
                st.rerun()

    current_keywords = st.session_state.keywords[selected_category]
    if current_keywords:
        st.write("ë“±ë¡ëœ í‚¤ì›Œë“œ:")
        kw_cols = st.columns(4)
        for i, kw in enumerate(current_keywords):
            if kw_cols[i % 4].button(f"âŒ {kw}", key=f"del_{kw}"):
                st.session_state.keywords[selected_category].remove(kw)
                # [ìˆ˜ì •] í‚¤ì›Œë“œ ì‚­ì œ ì‹œ íŒŒì¼ ì €ì¥ í˜¸ì¶œ
                save_keywords(st.session_state.keywords)
                st.rerun()
    else:
        st.caption("ë“±ë¡ëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

# ==========================================
# 4. í¬ë¡¤ë§ ì‹¤í–‰
# ==========================================
if update_clicked:
    if debug_mode:
        st.warning("ğŸ ë””ë²„ê¹… ëª¨ë“œê°€ ì¼œì ¸ ìˆìŠµë‹ˆë‹¤. ìƒì„¸ ë¡œê·¸ê°€ ì•„ë˜ì— í‘œì‹œë©ë‹ˆë‹¤.")
        
    st.info(f"ê¸°ê°„: {start_date} ~ {end_date} | í‚¤ì›Œë“œ ìˆ˜: {len(current_keywords)}ê°œ")
    
    with st.spinner(f"'{selected_category}' ê¸°ì‚¬ ìˆ˜ì§‘ ì¤‘..."):
        perform_crawling(selected_category, start_date, end_date, debug_mode)
        
    st.session_state.last_update = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.rerun()

st.divider()

if st.session_state.last_update:
    st.caption(f"Last Updated: {st.session_state.last_update}")

st.subheader(f"ğŸ“° Latest Articles")
data = st.session_state.news_data.get(selected_category, [])

if data:
    df_display = pd.DataFrame(data)
    df_display['Date'] = df_display['Date'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M'))
    
    for index, row in df_display.iterrows():
        with st.container():
            st.markdown(f"**[{row['Title']}]({row['Link']})**")
            st.caption(f"{row['Source']} | {row['Date']} | Keyword: {row['Keyword']}")
            st.divider()
else:
    if st.session_state.last_update:
        st.warning("í•´ë‹¹ ê¸°ê°„ì— ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("Update News ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
