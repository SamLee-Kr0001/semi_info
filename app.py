import streamlit as st
import pandas as pd
import requests
import urllib3
from urllib.parse import quote
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import json
import os
import re
import concurrent.futures # [NEW] ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ëª¨ë“ˆ

# [í•„ìˆ˜] ë²ˆì—­ ë¼ì´ë¸ŒëŸ¬ë¦¬
from deep_translator import GoogleTranslator

# Google Gemini
import google.generativeai as genai

# ==========================================
# 0. í˜ì´ì§€ ì„¤ì • ë° CSS
# ==========================================
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

st.set_page_config(layout="wide", page_title="Semi-Insight Hub", page_icon="ğŸ’ ")

st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@300;400;500;600;700&display=swap');
        
        html, body, [class*="css"] {
            font-family: 'Pretendard', sans-serif;
            background-color: #F8FAFC;
            color: #1E293B;
        }
        
        .stApp { background-color: #F8FAFC; }

        /* ë‰´ìŠ¤ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
        .news-title {
            font-size: 16px !important;
            font-weight: 700 !important;
            color: #111827 !important;
            text-decoration: none;
            line-height: 1.4;
            display: block;
            margin-bottom: 6px;
        }
        .news-title:hover {
            color: #2563EB !important;
            text-decoration: underline;
        }
        
        .news-snippet {
            font-size: 13.5px !important;
            color: #475569 !important;
            line-height: 1.5;
            margin-bottom: 10px;
        }

        .news-meta {
            font-size: 12px !important;
            color: #94A3B8 !important;
        }

        .control-box {
            background-color: #FFFFFF;
            padding: 15px 20px;
            border-radius: 12px;
            border: 1px solid #E2E8F0;
            margin-bottom: 20px;
        }
        
        button[kind="secondary"] {
            height: 28px !important;
            font-size: 12px !important;
            padding: 0 10px !important;
            border-radius: 14px !important;
        }
    </style>
""", unsafe_allow_html=True)

CATEGORIES = [
    "ê¸°ì—…ì •ë³´", "ë°˜ë„ì²´ ì •ë³´", "Photoresist", "Wet chemical", "CMP Slurry", 
    "Process Gas", "Precursor", "Metal target", "Wafer", "Package"
]

# ==========================================
# 1. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================
KEYWORD_FILE = 'keywords.json'

def load_keywords():
    data = {cat: [] for cat in CATEGORIES}
    if os.path.exists(KEYWORD_FILE):
        try:
            with open(KEYWORD_FILE, 'r', encoding='utf-8') as f:
                loaded = json.load(f)
            for k, v in loaded.items():
                if k in data: data[k] = v
        except: pass
    return data

def save_keywords(data):
    try:
        with open(KEYWORD_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except: pass

if 'keywords' not in st.session_state: st.session_state.keywords = load_keywords()
if 'news_data' not in st.session_state: st.session_state.news_data = {cat: [] for cat in CATEGORIES}
if 'last_update' not in st.session_state: st.session_state.last_update = None

# ==========================================
# 2. ë¡œì§: í¬ë¡¤ë§ & ë³‘ë ¬ ë²ˆì—­ & AI
# ==========================================

# [NEW] ë‹¨ì¼ í…ìŠ¤íŠ¸ ë²ˆì—­ í•¨ìˆ˜ (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)
def safe_translate(text):
    if not text: return ""
    try:
        # 1000ì ì œí•œ
        return GoogleTranslator(source='auto', target='ko').translate(text[:999])
    except:
        return text

# [NEW] ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ ë³‘ë ¬ ë²ˆì—­ ì²˜ë¦¬ê¸° (ì†ë„ ê°œì„ ì˜ í•µì‹¬)
def parallel_translate_articles(articles):
    # ë²ˆì—­ì´ í•„ìš”í•œ ê¸°ì‚¬(í•´ì™¸)ë§Œ ì‹ë³„
    tasks = []
    for article in articles:
        # KRì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ë²ˆì—­ ëŒ€ìƒ
        if 'KR' not in article.get('Country', 'KR'):
            tasks.append(article)
    
    if not tasks:
        return articles

    # ThreadPoolë¡œ ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ 10ê°œ ë™ì‹œ ì‘ì—…)
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        # ì œëª© ë²ˆì—­ Future ìƒì„±
        title_futures = {executor.submit(safe_translate, a['Title']): a for a in tasks}
        # ìš”ì•½ ë²ˆì—­ Future ìƒì„±
        snip_futures = {executor.submit(safe_translate, a['Snippet']): a for a in tasks}
        
        # ê²°ê³¼ ìˆ˜ì§‘ (ì œëª©)
        for future in concurrent.futures.as_completed(title_futures):
            article = title_futures[future]
            try:
                trans_title = future.result()
                if trans_title and trans_title != article['Title']:
                    article['Title'] = trans_title
            except: pass

        # ê²°ê³¼ ìˆ˜ì§‘ (ìš”ì•½)
        for future in concurrent.futures.as_completed(snip_futures):
            article = snip_futures[future]
            try:
                trans_snip = future.result()
                if trans_snip and trans_snip != article['Snippet']:
                    article['Snippet'] = f"ğŸŒ {trans_snip}"
            except: pass
            
    return articles

def make_smart_query(keyword, country_code):
    base_kw = keyword
    negatives = "-TikTok -í‹±í†¡ -douyin -dance -shorts -reels -viral -music -game -soccer"
    contexts = {
        'KR': "(ë°˜ë„ì²´ OR ì†Œì OR ê³µì • OR ì†Œì¬ OR íŒŒìš´ë“œë¦¬ OR íŒ¹ OR ì–‘ì‚°)",
        'CN': "(åŠå¯¼ä½“ OR èŠ¯ç‰‡ OR æ™¶åœ† OR å…‰åˆ»èƒ¶ OR èš€åˆ» OR å°è£…)",
        'HK': "(åŠå¯¼ä½“ OR èŠ¯ç‰‡ OR æ™¶åœ† OR å…‰åˆ»èƒ¶ OR èš€åˆ» OR å°è£…)",
        'TW': "(åŠå°é«” OR æ™¶ç‰‡ OR æ™¶åœ“ OR å…‰é˜» OR è•åˆ» OR å°è£)",
        'JP': "(åŠå°ä½“ OR ã‚·ãƒªã‚³ãƒ³ OR ã‚¦ã‚§ãƒ¼ãƒ OR ãƒ¬ã‚¸ã‚¹ãƒˆ)",
        'US': "(semiconductor OR chip OR fab OR foundry OR wafer OR lithography)"
    }
    context = contexts.get(country_code, contexts['US'])
    return f'{base_kw} AND {context} {negatives}'

def filter_with_gemini(articles, api_key):
    if not articles or not api_key: return articles
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        content_text = ""
        for i, item in enumerate(articles[:40]):
            safe_snip = re.sub(r'[^\w\s]', '', item.get('Snippet', ''))[:100]
            content_text += f"ID_{i+1} | Title: {item['Title']} | Snip: {safe_snip}\n"
            
        prompt = f"""
        Role: Semiconductor Analyst.
        Task: Filter noise. Keep B2B Tech/Fab/Materials.
        Data: {content_text}
        Output: IDs ONLY (e.g., 1, 3).
        """
        response = model.generate_content(prompt)
        nums = re.findall(r'\d+', response.text)
        valid_indices = [int(n)-1 for n in nums]
        filtered = []
        for idx in valid_indices:
            if 0 <= idx < len(articles):
                articles[idx]['AI_Verified'] = True
                filtered.append(articles[idx])
        return filtered if filtered else articles
    except: return articles

def crawl_google_rss(keyword, country_code, language):
    results = []
    smart_query = make_smart_query(keyword, country_code)
    url = f"https://news.google.com/rss/search?q={quote(smart_query)}&hl={language}&gl={country_code}&ceid={country_code}:{language}"
    
    try:
        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=5, verify=False)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'xml')
            for item in soup.find_all('item')[:5]: # í‚¤ì›Œë“œ ë‹¹ 5ê°œ ì œí•œ
                src = item.source.text if item.source else "Google"
                raw_d = item.description.text if item.description else ""
                snip = BeautifulSoup(raw_d, "html.parser").get_text(strip=True)[:200]
                title = item.title.text

                # [ìµœì í™”] ì—¬ê¸°ì„œ ë²ˆì—­í•˜ì§€ ì•Šê³  ì›ë³¸ë§Œ ì €ì¥
                pub_date = item.pubDate.text if item.pubDate else str(datetime.now())
                try: dt_obj = pd.to_datetime(pub_date).to_pydatetime()
                except: dt_obj = datetime.now()

                results.append({
                    'Title': title, 'Source': src, 'Date': dt_obj,
                    'Link': item.link.text, 'Keyword': keyword, 'Snippet': snip,
                    'AI_Verified': False,
                    'Country': country_code # ë²ˆì—­ ëŒ€ìƒ ì‹ë³„ìš©
                })
    except: pass
    return results

def perform_crawling(category, start_date, end_date, api_key):
    kws = st.session_state.keywords.get(category, [])
    if not kws: return
    start_dt = datetime.combine(start_date, datetime.min.time())
    end_dt = datetime.combine(end_date, datetime.max.time())
    
    with st.spinner(f"ğŸš€ '{category}' ë‰´ìŠ¤ ê³ ì† ìˆ˜ì§‘ ì¤‘..."):
        all_news = []
        for kw in kws:
            # KR, US, TW, CN ë“± ìˆ˜ì§‘
            for cc, lang in [('KR','ko'), ('US','en'), ('TW','zh-TW'), ('CN', 'zh-CN')]:
                all_news.extend(crawl_google_rss(kw, cc, lang))
        
        # 1. ë°ì´í„° ì •ë¦¬ (ë‚ ì§œ í•„í„° ë° ì¤‘ë³µ ì œê±°)
        df = pd.DataFrame(all_news)
        if not df.empty:
            df = df[(df['Date'] >= start_dt) & (df['Date'] <= end_dt)]
            df = df.drop_duplicates(subset=['Title']).sort_values('Date', ascending=False)
            
            # 2. ìƒìœ„ 60ê°œë§Œ ë‚¨ê¹€ (ë²ˆì—­ ëŒ€ìƒ ìµœì†Œí™”)
            final_list = df.head(60).to_dict('records')
            
            # 3. [ìµœì í™”] ì‚´ì•„ë‚¨ì€ ê¸°ì‚¬ë§Œ ë³‘ë ¬ ë²ˆì—­ ì‹¤í–‰
            if final_list:
                final_list = parallel_translate_articles(final_list)

            # 4. AI í•„í„°ë§
            if api_key and final_list:
                final_list = filter_with_gemini(final_list, api_key)
            
            st.session_state.news_data[category] = final_list
        else:
             st.session_state.news_data[category] = []

# ==========================================
# 3. Sidebar
# ==========================================
with st.sidebar:
    st.header("Semi-Insight")
    st.divider()
    st.subheader("ğŸ“‚ Category")
    selected_category = st.radio("ì¹´í…Œê³ ë¦¬", CATEGORIES, label_visibility="collapsed")
    st.divider()
    with st.expander("ğŸ” API Key"):
        api_key = st.text_input("Key", type="password")
        if not api_key and "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            st.caption("Loaded")

# ==========================================
# 4. Main UI
# ==========================================
c_head, c_info = st.columns([3, 1])
with c_head: st.title(selected_category)
with c_info: 
    if st.session_state.last_update:
        st.markdown(f"<div style='text-align:right; font-size:12px; color:#888;'>Last Update<br><b>{st.session_state.last_update}</b></div>", unsafe_allow_html=True)

# ì»¨íŠ¸ë¡¤ íŒ¨ë„
with st.container(border=True):
    c1, c2, c3 = st.columns([1.5, 2.5, 1])
    with c1:
        period = st.selectbox("ê¸°ê°„", ["1 Month", "3 Months", "Custom"], label_visibility="collapsed")
        today = datetime.now().date()
        if period == "1 Month": s, e = today - timedelta(days=30), today
        elif period == "3 Months": s, e = today - timedelta(days=90), today
        else:
            dr = st.date_input("ë‚ ì§œ", (today-timedelta(7), today), label_visibility="collapsed")
            if len(dr)==2: s, e = dr
            else: s, e = dr[0], dr[0]
            
    with c2:
        new_kw = st.text_input("í‚¤ì›Œë“œ", placeholder="ì˜ˆ: HBM", label_visibility="collapsed")
        
    with c3:
        b1, b2 = st.columns(2)
        with b1:
            if st.button("ì¶”ê°€", use_container_width=True):
                if new_kw and new_kw not in st.session_state.keywords[selected_category]:
                    st.session_state.keywords[selected_category].append(new_kw)
                    save_keywords(st.session_state.keywords)
                    st.rerun()
        with b2:
            if st.button("ì‹¤í–‰", type="primary", use_container_width=True):
                perform_crawling(selected_category, s, e, api_key)
                st.session_state.last_update = datetime.now().strftime("%Y-%m-%d %H:%M")
                st.rerun()

    # í‚¤ì›Œë“œ íƒœê·¸
    curr_kws = st.session_state.keywords.get(selected_category, [])
    if curr_kws:
        st.write("")
        cols = st.columns(8)
        for i, kw in enumerate(curr_kws):
            if cols[i%8].button(f"{kw} Ã—", key=f"d_{kw}", type="secondary"):
                st.session_state.keywords[selected_category].remove(kw)
                save_keywords(st.session_state.keywords)
                st.rerun()

# ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
data = st.session_state.news_data.get(selected_category, [])

if data:
    st.divider()
    m1, m2 = st.columns(2)
    m1.metric("Collected", len(data))
    m2.metric("AI Verified", sum(1 for d in data if d.get('AI_Verified')))
    st.markdown("<br>", unsafe_allow_html=True)
    
    for i in range(0, len(data), 2):
        row_items = data[i : i+2]
        cols = st.columns(2)
        for idx, item in enumerate(row_items):
            with cols[idx]:
                with st.container(border=True):
                    # ë©”íƒ€ ì •ë³´
                    st.markdown(f"""
                        <div class="news-meta" style="display:flex; justify-content:space-between; margin-bottom:5px;">
                            <span>ğŸ“° {item['Source']}</span>
                            <span>{item['Date'].strftime('%Y-%m-%d')}</span>
                        </div>
                    """, unsafe_allow_html=True)
                    
                    # ì œëª© (16px)
                    st.markdown(f'<a href="{item["Link"]}" target="_blank" class="news-title">{item["Title"]}</a>', unsafe_allow_html=True)
                    
                    # ìš”ì•½ (13.5px)
                    if item.get('Snippet'):
                        st.markdown(f'<div class="news-snippet">{item["Snippet"]}</div>', unsafe_allow_html=True)
                    
                    st.markdown("---")
                    
                    # í•˜ë‹¨ íƒœê·¸
                    ft1, ft2 = st.columns([3, 1])
                    with ft1:
                        st.markdown(f"<span style='background:#F1F5F9; color:#64748B; padding:3px 8px; border-radius:4px; font-size:11px;'>#{item['Keyword']}</span>", unsafe_allow_html=True)
                    with ft2:
                        if item.get('AI_Verified'):
                            st.markdown("<span style='color:#4F46E5; font-size:11px; font-weight:bold;'>âœ¨ AI Pick</span>", unsafe_allow_html=True)
else:
    with st.container(border=True):
        st.markdown("<div style='text-align:center; padding:30px; color:#999;'>ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.<br>ìƒë‹¨ì˜ 'ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.</div>", unsafe_allow_html=True)
