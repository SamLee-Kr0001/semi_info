import streamlit as st
import pandas as pd
import requests
import urllib3
from urllib.parse import quote
from bs4 import BeautifulSoup
from datetime import datetime, timedelta, time as dt_time
import json
import os
import re
import time
import yfinance as yf
from github import Github
import concurrent.futures  # [ì¶”ê°€] ì£¼ì‹ ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ëª¨ë“ˆ

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==========================================
# 0. í˜ì´ì§€ ì„¤ì •
# ==========================================
st.set_page_config(layout="wide", page_title="Semi-Insight Hub", page_icon="ğŸ’ ")

CATEGORIES = ["Daily Report", "P&C ì†Œì¬", "EDTW ì†Œì¬", "PKG ì†Œì¬"]
KEYWORD_FILE = 'keywords.json'
HISTORY_FILE = 'daily_history.json'

if 'news_data' not in st.session_state:
    st.session_state.news_data = {cat: [] for cat in CATEGORIES}
if 'daily_history' not in st.session_state:
    st.session_state.daily_history = []

st.markdown("""
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    
    <style>
        html, body, [class*="css"] { font-family: 'Inter', sans-serif; }
        .stApp { background-color: #F8FAFC; }
        
        .report-box { background-color: #FFFFFF; padding: 50px; border-radius: 12px; border: 1px solid #E2E8F0; box-shadow: 0 4px 20px rgba(0,0,0,0.05); margin-bottom: 30px; line-height: 1.8; color: #334155; font-size: 16px; }
        .news-card { background: white; padding: 15px; border-radius: 10px; border: 1px solid #E2E8F0; margin-bottom: 10px; }
        .news-title { font-size: 16px !important; font-weight: 700 !important; color: #111827 !important; text-decoration: none; display: block; margin-bottom: 6px; }
        .news-meta { font-size: 12px !important; color: #94A3B8 !important; }
        
        /* ì£¼ì‹ ì •ë³´ ìŠ¤íƒ€ì¼ */
        .stock-row { display: flex; justify-content: space-between; align-items: center; font-size: 14px; padding: 5px 0; border-bottom: 1px dashed #e2e8f0; }
        .stock-name { font-weight: 600; color: #334155; }
        .stock-price { font-family: 'Consolas', monospace; font-weight: 600; font-size: 14px; }
        .up-color { color: #DC2626 !important; }
        .down-color { color: #2563EB !important; }
        .flat-color { color: #64748B !important; }
        .stock-header { font-size: 13px; font-weight: 700; color: #475569; margin-top: 15px; margin-bottom: 5px; border-bottom: 1px solid #E2E8F0; padding-bottom: 4px; }
        .ref-link { font-size: 0.9em; color: #555; text-decoration: none; display: block; margin-bottom: 6px; padding: 5px; border-radius: 4px; transition: background 0.2s; }
        
        section[data-testid="stSidebar"] { background-color: #FFFFFF; border-right: 1px solid #E2E8F0; }
        div.stButton > button { border-radius: 8px; font-weight: 600; transition: all 0.2s ease-in-out; }
        .streamlit-expanderHeader { background-color: #FFFFFF; border-radius: 8px; }
        a { text-decoration: none; }
    </style>
""", unsafe_allow_html=True)

# ì£¼ì‹ í‹°ì»¤
STOCK_CATEGORIES = {
    "ğŸ­ Chipmakers": {"SK Hynix": "000660.KS", "Samsung": "005930.KS", "Micron": "MU", "TSMC": "TSM", "Intel": "INTC", "AMD": "AMD", "SMIC": "0981.HK"},
    "ğŸ§  AI ": {"NVIDIA": "NVDA", "Apple": "AAPL", "Alphabet (Google)": "GOOGL", "Microsoft": "MSFT", "Meta": "META", "Amazon": "AMZN", "Tesla": "TSLA", "IBM": "IBM", "Oracle": "ORCL", "Broadcom": "AVGO"},
    "ğŸ§ª Materials": {"Soulbrain": "357780.KQ", "Dongjin": "005290.KQ", "Hana Mat": "166090.KQ", "Wonik Mat": "104830.KQ", "TCK": "064760.KQ", "Foosung": "093370.KS", "PI Adv": "178920.KS", "ENF": "102710.KQ", "TEMC": "425040.KQ", "YC Chem": "112290.KQ", "Samsung SDI": "006400.KS", "Shin-Etsu": "4063.T", "Sumco": "3436.T", "Merck": "MRK.DE", "Entegris": "ENTG", "TOK": "4186.T", "Resonac": "4004.T", "Air Prod": "APD", "Linde": "LIN", "Qnity": "Q", "Nissan Chem": "4021.T", "Sumitomo": "4005.T"},
    "âš™ï¸ Equipment": {"ASML": "ASML", "AMAT": "AMAT", "Lam Res": "LRCX", "TEL": "8035.T", "KLA": "KLAC", "Advantest": "6857.T", "Hitachi HT": "8036.T", "Hanmi": "042700.KS", "Wonik IPS": "240810.KQ", "Jusung": "036930.KQ", "EO Tech": "039030.KQ", "Techwing": "089030.KQ", "Eugene": "084370.KQ", "PSK": "319660.KQ", "Zeus": "079370.KQ", "Top Eng": "065130.KQ"}
}

# ==========================================
# 1. ë°ì´í„° ê´€ë¦¬ (GitHub Auto-Sync)
# ==========================================
def sync_to_github(filename, content_data):
    if "GITHUB_TOKEN" not in st.secrets or "REPO_NAME" not in st.secrets: return False
    try:
        g = Github(st.secrets["GITHUB_TOKEN"])
        repo = g.get_repo(st.secrets["REPO_NAME"])
        content_str = json.dumps(content_data, ensure_ascii=False, indent=4)
        try:
            contents = repo.get_contents(filename)
            repo.update_file(contents.path, f"Update {filename}", content_str, contents.sha)
        except:
            repo.create_file(filename, f"Create {filename}", content_str)
        return True
    except: return False

def load_keywords():
    data = {cat: [] for cat in CATEGORIES}
    if "GITHUB_TOKEN" in st.secrets:
        try:
            g = Github(st.secrets["GITHUB_TOKEN"])
            repo = g.get_repo(st.secrets["REPO_NAME"])
            contents = repo.get_contents(KEYWORD_FILE)
            loaded = json.loads(contents.decoded_content.decode("utf-8"))
            return loaded
        except: pass
    if os.path.exists(KEYWORD_FILE):
        try:
            with open(KEYWORD_FILE, 'r', encoding='utf-8') as f:
                loaded = json.load(f)
            for k, v in loaded.items():
                if k in data: data[k] = v
        except: pass
    if not data.get("Daily Report"): 
        data["Daily Report"] = ["ë°˜ë„ì²´", "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤"] 
    return data

def save_keywords(data):
    try:
        with open(KEYWORD_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except: pass
    sync_to_github(KEYWORD_FILE, data)

def load_daily_history_from_source():
    if "GITHUB_TOKEN" in st.secrets:
        try:
            g = Github(st.secrets["GITHUB_TOKEN"])
            repo = g.get_repo(st.secrets["REPO_NAME"])
            contents = repo.get_contents(HISTORY_FILE)
            return json.loads(contents.decoded_content.decode("utf-8"))
        except: pass
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: return []
    return []

if 'news_data' not in st.session_state:
    st.session_state.news_data = {cat: [] for cat in CATEGORIES}
if 'keywords' not in st.session_state:
    st.session_state.keywords = load_keywords()
if 'daily_history' not in st.session_state:
    st.session_state.daily_history = load_daily_history_from_source()

def save_daily_history(new_report_data):
    current_history = [h for h in st.session_state.daily_history if h['date'] != new_report_data['date']]
    current_history.insert(0, new_report_data)
    st.session_state.daily_history = current_history
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(current_history, f, ensure_ascii=False, indent=4)
    except: pass
    sync_to_github(HISTORY_FILE, current_history)

# [ìˆ˜ì •] ì£¼ì‹ ê°œë³„ ìˆ˜ì§‘ í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
def fetch_single_stock(name, symbol):
    try:
        ticker = yf.Ticker(symbol)
        # 1. fast_infoë¥¼ ìš°ì„  ì‹œë„ (ê°€ì¥ ìµœì‹ /ì •í™•)
        try:
            current = ticker.fast_info['last_price']
            prev = ticker.fast_info['previous_close']
        except:
            # 2. ì‹¤íŒ¨ ì‹œ history ì¡°íšŒ
            hist = ticker.history(period="1d")
            if not hist.empty:
                current = hist['Close'].iloc[-1]
                prev = ticker.info.get('previousClose', current) # infoëŠ” ëŠë¦´ ìˆ˜ ìˆìŒ
            else:
                # 3. ë°ì´í„°ê°€ ì•„ì˜ˆ ì—†ìœ¼ë©´ 5ì¼ì¹˜ë¡œ fallback
                hist_5d = ticker.history(period="5d")
                if len(hist_5d) >= 1:
                    current = hist_5d['Close'].iloc[-1]
                    prev = hist_5d['Close'].iloc[-2] if len(hist_5d) >= 2 else current
                else:
                    return name, None

        if current is None: return name, None

        change = current - prev
        pct = (change / prev) * 100
        
        # í†µí™” ê¸°í˜¸ ì„¤ì •
        if ".KS" in symbol or ".KQ" in symbol: cur_sym = "â‚©"
        elif ".T" in symbol: cur_sym = "Â¥"
        elif ".HK" in symbol: cur_sym = "HK$"
        elif ".DE" in symbol: cur_sym = "â‚¬"
        else: cur_sym = "$"
        
        fmt_price = f"{cur_sym}{current:,.0f}" if cur_sym in ["â‚©", "Â¥"] else f"{cur_sym}{current:,.2f}"
        
        if change > 0: color_class, arrow, sign = "up-color", "â–²", "+"
        elif change < 0: color_class, arrow, sign = "down-color", "â–¼", ""
        else: color_class, arrow, sign = "flat-color", "-", ""
        
        html_str = f"""
        <div class="stock-row">
            <span class="stock-name">{name}</span>
            <span class="stock-price {color_class}">
                {fmt_price} <span style="font-size:0.9em; margin-left:3px;">{arrow} {sign}{pct:.2f}%</span>
            </span>
        </div>
        """
        return name, html_str
    except:
        return name, None

# [ìˆ˜ì •] ë³‘ë ¬ ì²˜ë¦¬ ì ìš©ëœ ì£¼ì‹ ìˆ˜ì§‘ í•¨ìˆ˜ (ì†ë„ ê°œì„ )
@st.cache_data(ttl=300)
def get_stock_prices_grouped():
    result_map = {}
    # ëª¨ë“  í‹°ì»¤ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ í‰íƒ„í™”
    all_tickers = []
    for cat, items in STOCK_CATEGORIES.items():
        for name, symbol in items.items():
            all_tickers.append((name, symbol))
            
    # ë³‘ë ¬ ì‹¤í–‰ (ìµœëŒ€ 10ê°œ ìŠ¤ë ˆë“œ)
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        future_to_stock = {executor.submit(fetch_single_stock, name, symbol): name for name, symbol in all_tickers}
        for future in concurrent.futures.as_completed(future_to_stock):
            try:
                name, html = future.result()
                if html:
                    result_map[name] = html
            except: pass
            
    return result_map

# ==========================================
# 2. ë‰´ìŠ¤ ìˆ˜ì§‘ (ê¸°ì¡´ ìœ ì§€)
# ==========================================
def fetch_news(keywords, days=1, limit=40, strict_time=False, start_dt=None, end_dt=None):
    all_items = []
    if not (strict_time and start_dt and end_dt):
        now_kst = datetime.utcnow() + timedelta(hours=9)
        end_dt = datetime(now_kst.year, now_kst.month, now_kst.day, 6, 0, 0)
        if now_kst.hour < 6: end_dt -= timedelta(days=1)
        start_dt = end_dt - timedelta(hours=18)
    
    per_kw_limit = 3 if len(keywords) > 4 else 7

    for kw in keywords:
        url = f"https://news.google.com/rss/search?q={quote(kw)}+when:{days}d&hl=ko&gl=KR&ceid=KR:ko"
        try:
            res = requests.get(url, timeout=5, verify=False)
            soup = BeautifulSoup(res.content, 'xml')
            items = soup.find_all('item')
            kw_collected = 0
            for item in items:
                is_valid = True
                if strict_time:
                    try:
                        pub_date_str = item.pubDate.text
                        pub_date = datetime.strptime(pub_date_str, "%a, %d %b %Y %H:%M:%S %Z")
                        pub_date_kst = pub_date + timedelta(hours=9)
                        if not (start_dt <= pub_date_kst <= end_dt): is_valid = False
                    except: is_valid = True 
                
                if is_valid:
                    if not any(i['Title'] == item.title.text for i in all_items):
                        all_items.append({
                            'Title': item.title.text,
                            'Link': item.link.text,
                            'Date': item.pubDate.text,
                            'Source': item.source.text if item.source else "Google News",
                            'ParsedDate': pub_date_kst if strict_time else None
                        })
                        kw_collected += 1
                if kw_collected >= per_kw_limit: break
        except: pass
        time.sleep(0.1)
        
    df = pd.DataFrame(all_items)
    if not df.empty:
        df = df.drop_duplicates(subset=['Title'])
        if strict_time: df = df.sort_values(by='ParsedDate', ascending=False)
        return df.head(limit).to_dict('records')
    return []

# ==========================================
# 2-1. ê¸€ë¡œë²Œ ë‰´ìŠ¤
# ==========================================
def translate_text_batch(api_key, texts, target_lang="Korean"):
    if not texts: return []
    model = "gemini-1.5-flash"
    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
        res = requests.get(url, timeout=5)
        if res.status_code == 200:
            models = [m['name'].replace("models/", "") for m in res.json().get('models', []) if 'generateContent' in m.get('supportedGenerationMethods', [])]
            if models: model = models[0]
    except: pass
    prompt = f"Translate the following list of texts to {target_lang}. Return ONLY the translated strings in a JSON array format [\"text1\", \"text2\"...].\n\nTexts: {json.dumps(texts)}"
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    try:
        response = requests.post(url, headers=headers, json=data, timeout=30)
        if response.status_code == 200:
            raw_text = response.json()['candidates'][0]['content']['parts'][0]['text']
            match = re.search(r'\[.*\]', raw_text, re.DOTALL)
            if match: return json.loads(match.group(0))
    except: pass
    return texts

def get_translated_keywords(api_key, keyword):
    prompt = f"Translate '{keyword}' into English, Japanese, Traditional Chinese(TW), Simplified Chinese(CN). Return JSON: {{'EN':'..','JP':'..','TW':'..','CN':'..'}}"
    model = "gemini-1.5-flash"
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    try:
        res = requests.post(url, headers=headers, json=data, timeout=10)
        if res.status_code == 200:
            txt = res.json()['candidates'][0]['content']['parts'][0]['text']
            match = re.search(r'\{.*\}', txt, re.DOTALL)
            if match: return json.loads(match.group(0))
    except: pass
    return {"EN": keyword, "JP": keyword, "TW": keyword, "CN": keyword}

def fetch_news_global(api_key, keywords, days=3):
    TARGETS = {
        "KR": {"gl": "KR", "hl": "ko", "key": "KR"},
        "US": {"gl": "US", "hl": "en", "key": "EN"},
        "JP": {"gl": "JP", "hl": "ja", "key": "JP"},
        "TW": {"gl": "TW", "hl": "zh-TW", "key": "TW"},
        "CN": {"gl": "CN", "hl": "zh-CN", "key": "CN"}
    }
    all_raw_items = []
    per_kw_limit = 3 if len(keywords) > 4 else 5
    for kw in keywords:
        trans_map = get_translated_keywords(api_key, kw)
        trans_map["KR"] = kw
        for country, conf in TARGETS.items():
            search_term = trans_map.get(conf["key"], kw)
            url = f"https://news.google.com/rss/search?q={quote(search_term)}+when:{days}d&hl={conf['hl']}&gl={conf['gl']}&ceid={conf['gl']}:{conf['hl']}"
            try:
                res = requests.get(url, timeout=3, verify=False)
                soup = BeautifulSoup(res.content, 'xml')
                items = soup.find_all('item')
                kw_added = 0
                for item in items:
                    all_raw_items.append({
                        'Title': item.title.text,
                        'Link': item.link.text,
                        'Date': item.pubDate.text,
                        'Source': f"[{country}] {item.source.text if item.source else 'Google News'}",
                        'Lang': conf['key']
                    })
                    kw_added += 1
                    if kw_added >= per_kw_limit: break
            except: pass
            time.sleep(0.1)
    if not all_raw_items: return []
    df = pd.DataFrame(all_raw_items)
    df = df.drop_duplicates(subset=['Title'])
    items_to_process = df.head(40).to_dict('records')
    titles_to_translate = [x['Title'] for x in items_to_process if x['Lang'] != "KR"]
    indices_to_translate = [i for i, x in enumerate(items_to_process) if x['Lang'] != "KR"]
    if titles_to_translate:
        translated_titles = translate_text_batch(api_key, titles_to_translate)
        for idx, new_title in zip(indices_to_translate, translated_titles):
            if idx < len(items_to_process):
                items_to_process[idx]['Title'] = f"{new_title} <span style='font-size:0.8em; color:#94A3B8;'>({items_to_process[idx]['Title']})</span>"
    return items_to_process

# ==========================================
# 3. AI ë¦¬í¬íŠ¸ ìƒì„± (ê¸°ì¡´ ìœ ì§€)
# ==========================================
def get_available_models(api_key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    try:
        res = requests.get(url, timeout=10)
        if res.status_code == 200:
            data = res.json()
            return [m['name'].replace("models/", "") for m in data.get('models', []) if 'generateContent' in m.get('supportedGenerationMethods', [])]
    except: pass
    return []

def inject_links_to_report(report_text, news_data):
    def replace_match(match):
        try:
            idx = int(match.group(1)) - 1
            if 0 <= idx < len(news_data):
                link = news_data[idx]['Link']
                return f"<a href='{link}' target='_blank' class='text-blue-600 font-bold hover:underline'>[{match.group(1)}]</a>"
        except: pass
        return match.group(0)
    return re.sub(r'\[(\d+)\]', replace_match, report_text)

def generate_report_with_citations(api_key, news_data):
    models = get_available_models(api_key)
    if not models:
        models = ["gemini-1.5-flash", "gemini-2.0-flash", "gemini-1.5-pro"]
    else:
        if "gemini-1.5-flash" in models:
            models.remove("gemini-1.5-flash")
            models.insert(0, "gemini-1.5-flash")
    
    news_context = ""
    for i, item in enumerate(news_data):
        clean_title = re.sub(r'<[^>]+>', '', item['Title'])
        news_context += f"[{i+1}] {clean_title} (Source: {item['Source']})\n"

    prompt = f"""
    ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ë°˜ë„ì²´ íˆ¬ì ë° ì „ëµ ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. 
    ì œê³µëœ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ **[ì¼ì¼ ë°˜ë„ì²´ ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ]**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

    **[ì‘ì„± ì›ì¹™ - ë§¤ìš° ì¤‘ìš”]**
    1. **ë‹¨ìˆœ ìš”ì•½ ê¸ˆì§€**: ë‰´ìŠ¤ ì œëª©ì„ ë‹¨ìˆœíˆ ë‚˜ì—´í•˜ê±°ë‚˜ ë²ˆì—­í•˜ì§€ ë§ˆì„¸ìš”.
    2. **ì„œìˆ í˜• ì‘ì„±**: ì´ìŠˆë³„ë¡œ í˜„ìƒ/ì›ì¸/ì „ë§ì„ ê°œì¡°ì‹(Bullet points)ìœ¼ë¡œ ë‚˜ëˆ„ì§€ ë§ê³ , **í•˜ë‚˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë…¼ë¦¬ì  íë¦„ì„ ê°€ì§„ ì¤„ê¸€(Narrative Paragraph)**ë¡œ ì„œìˆ í•˜ì„¸ìš”. ì „ë¬¸ì ì¸ ë¬¸ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    3. **ê·¼ê±° ëª…ì‹œ**: ëª¨ë“  ì£¼ì¥ì´ë‚˜ ì‚¬ì‹¤ ì–¸ê¸‰ ì‹œ ë°˜ë“œì‹œ ì œê³µëœ ë‰´ìŠ¤ ë²ˆí˜¸ **[1], [2]**ë¥¼ ë¬¸ì¥ ëì— ì¸ìš©í•˜ì„¸ìš”.

    [ë‰´ìŠ¤ ë°ì´í„°]
    {news_context}
    
    [ë³´ê³ ì„œ êµ¬ì¡° (Markdown)]
    ## ğŸ“Š Executive Summary (ì‹œì¥ ì´í‰)
    - ì˜¤ëŠ˜ ë°˜ë„ì²´ ì‹œì¥ì˜ í•µì‹¬ ë¶„ìœ„ê¸°ì™€ ê°€ì¥ ì¤‘ìš”í•œ ë³€í™”ë¥¼ 3~4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½.

    ## ğŸš¨ Key Issues & Deep Dive (í•µì‹¬ ì´ìŠˆ ì‹¬ì¸µ ë¶„ì„)
    - ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ 2~3ê°€ì§€ë¥¼ ì„ ì •í•˜ì—¬ ì†Œì œëª©ì„ ë‹¬ê³  ë¶„ì„í•˜ì„¸ìš”.
    - **ì¤‘ìš”**: í˜„ìƒ, ì›ì¸, ì „ë§ì„ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•˜ì§€ ë§ê³ , **ê¹Šì´ ìˆëŠ” ì„œìˆ í˜• ë¬¸ë‹¨**ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì‚¬ê±´ì˜ ë°°ê²½ë¶€í„° íŒŒê¸‰ íš¨ê³¼ê¹Œì§€ ë§¤ë„ëŸ½ê²Œ ì—°ê²°ë˜ë„ë¡ í•˜ì„¸ìš”.
    - ë°˜ë“œì‹œ ì¸ìš© ë²ˆí˜¸[n]ë¥¼ í¬í•¨í•  ê²ƒ.

    ## ğŸ•¸ï¸ Supply Chain & Tech Trends (ê³µê¸‰ë§ ë° ê¸°ìˆ  ë™í–¥)
    - ë°˜ë„ì²´ ì†Œì¬ ê·¸ë¦¬ê³  ì†Œë¶€ì¥, íŒŒìš´ë“œë¦¬, ë©”ëª¨ë¦¬ ë“± ì„¹í„°ë³„ ì£¼ìš” ë‹¨ì‹ ì„ ì¢…í•©í•˜ì—¬ ì„œìˆ .

    ## ğŸ’¡ Analyst's View (íˆ¬ì ì•„ì´ë””ì–´)
    - ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ê°€ ì£¼ëŠ” ì‹œì‚¬ì ê³¼ í–¥í›„ ê´€ì „ í¬ì¸íŠ¸ í•œ ì¤„ ì •ë¦¬.
    """
    
    headers = {'Content-Type': 'application/json'}
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [{"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"}]
    }

    for model in models:
        if "vision" in model: continue
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
        try:
            response = requests.post(url, headers=headers, json=data, timeout=60)
            if response.status_code == 200:
                res_json = response.json()
                if 'candidates' in res_json and res_json['candidates']:
                    raw_text = res_json['candidates'][0]['content']['parts'][0]['text']
                    return True, inject_links_to_report(raw_text, news_data)
            elif response.status_code == 429:
                time.sleep(1) 
                continue
        except: continue
            
    return False, "AI ë¶„ì„ ì‹¤íŒ¨ (ëª¨ë“  ëª¨ë¸ ì‘ë‹µ ì—†ìŒ)"

# ==========================================
# 4. ë©”ì¸ ì•± UI
# ==========================================
with st.sidebar:
    st.markdown("<h2 class='text-2xl font-bold text-slate-800 mb-4'>Semi-Insight</h2>", unsafe_allow_html=True)
    selected_category = st.radio("ì¹´í…Œê³ ë¦¬", CATEGORIES, index=0)
    st.markdown("---")
    
    with st.expander("ğŸ” API Key ì„¤ì •"):
        user_key = st.text_input("Gemini API Key", type="password")
        if user_key: api_key = user_key
        elif "GEMINI_API_KEY" in st.secrets: api_key = st.secrets["GEMINI_API_KEY"]
        else: api_key = ""
    
    st.markdown("<div class='h-4'></div>", unsafe_allow_html=True)
    
    if "GITHUB_TOKEN" in st.secrets:
        st.markdown("<div class='text-xs text-green-600 font-bold mb-2'>âœ… GitHub Auto-Sync Active</div>", unsafe_allow_html=True)
    
    with st.expander("ğŸ“‰ Global Stock (ì‹¤ì‹œê°„)", expanded=True):
        if st.button("ğŸ”„ ì‹œì„¸ ì—…ë°ì´íŠ¸", use_container_width=True):
            get_stock_prices_grouped.clear()
            st.rerun()
        stock_data = get_stock_prices_grouped()
        if stock_data:
            for cat, items in STOCK_CATEGORIES.items():
                st.markdown(f"<div class='stock-header'>{cat}</div>", unsafe_allow_html=True)
                for name, symbol in items.items():
                    html_info = stock_data.get(name)
                    if html_info: st.markdown(html_info, unsafe_allow_html=True)

c_head, c_info = st.columns([3, 1])
with c_head: st.markdown(f"<h1 class='text-3xl font-bold text-slate-800 mb-2'>{selected_category}</h1>", unsafe_allow_html=True)

# ----------------------------------
# [Mode 1] Daily Report
# ----------------------------------
if selected_category == "Daily Report":
    st.markdown("<div class='bg-blue-50 text-blue-800 px-4 py-3 rounded-lg text-sm mb-6'>â„¹ï¸ ë§¤ì¼ ì˜¤ì „ 6ì‹œ ê¸°ì¤€ ë°˜ë„ì²´ ì •ë³´ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
    
    now_kst = datetime.utcnow() + timedelta(hours=9)
    if now_kst.hour < 6: target_date = (now_kst - timedelta(days=1)).date()
    else: target_date = now_kst.date()
    target_date_str = target_date.strftime('%Y-%m-%d')
    
    st.markdown(f"<div class='text-right text-sm text-slate-500 mb-4'>Report Date: <b>{target_date}</b></div>", unsafe_allow_html=True)

    with st.container(border=True):
        c1, c2 = st.columns([3, 1])
        new_kw = c1.text_input("ìˆ˜ì§‘ í‚¤ì›Œë“œ ì¶”ê°€", placeholder="ì˜ˆ: HBM, íŒ¨í‚¤ì§•", label_visibility="collapsed")
        if c2.button("ì¶”ê°€", use_container_width=True):
            if new_kw and new_kw not in st.session_state.keywords["Daily Report"]:
                st.session_state.keywords["Daily Report"].append(new_kw)
                save_keywords(st.session_state.keywords)
                st.rerun()
        
        daily_kws = st.session_state.keywords["Daily Report"]
        if daily_kws:
            st.write("")
            st.markdown("<div class='flex flex-wrap gap-2'>", unsafe_allow_html=True)
            cols = st.columns(len(daily_kws) if len(daily_kws) < 8 else 8)
            for i, kw in enumerate(daily_kws):
                if cols[i % 8].button(f"{kw} Ã—", key=f"del_{kw}"):
                    st.session_state.keywords["Daily Report"].remove(kw)
                    save_keywords(st.session_state.keywords)
                    st.rerun()
            st.markdown("</div>", unsafe_allow_html=True)
    
    # ì„¸ì…˜ ìš°ì„  í‘œì‹œ (í™”ë©´ ê¹œë¹¡ì„/ë°ì´í„° ì¦ë°œ ë°©ì§€)
    history = st.session_state.daily_history
    today_report = next((h for h in history if h['date'] == target_date_str), None)
    
    if not today_report:
        st.info("ğŸ“¢ ì˜¤ëŠ˜ì˜ ë¦¬í¬íŠ¸ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if st.button("ğŸš€ ê¸ˆì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘", type="primary"):
            status_box = st.status("ğŸš€ ë¦¬í¬íŠ¸ ìƒì„± í”„ë¡œì„¸ìŠ¤...", expanded=True)
            end_dt = datetime.combine(target_date, dt_time(6, 0))
            start_dt = end_dt - timedelta(hours=18)
            
            status_box.write("ğŸ“¡ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ (40ê±´)...")
            news_items = fetch_news(daily_kws, days=2, limit=40, strict_time=True, start_dt=start_dt, end_dt=end_dt)
            
            if not news_items:
                status_box.update(label="âš ï¸ ì¡°ê±´ ë¯¸ë‹¬. í™•ì¥ ê²€ìƒ‰ ì‹œë„...", state="running")
                time.sleep(1)
                news_items = fetch_news(daily_kws, days=1, limit=40, strict_time=False)
            
            if not news_items:
                status_box.update(label="âŒ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.", state="error")
            else:
                status_box.write(f"ğŸ§  AI ì‹¬ì¸µ ë¶„ì„ ì¤‘... ({len(news_items)}ê±´)")
                success, result = generate_report_with_citations(api_key, news_items)
                
                if success:
                    status_box.write("ğŸ’¾ ì €ì¥ ì¤‘...")
                    save_data = {'date': target_date_str, 'report': result, 'articles': news_items}
                    save_daily_history(save_data)
                    status_box.update(label="ğŸ‰ ì™„ë£Œ!", state="complete", expanded=False)
                    st.rerun()
                else:
                    status_box.update(label="âš ï¸ AI ë¶„ì„ ì‹¤íŒ¨", state="error")
                    st.error(result)
    else:
        st.success("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        if st.button("ğŸ”„ ë¦¬í¬íŠ¸ ë‹¤ì‹œ ë§Œë“¤ê¸°"):
            status_box = st.status("ğŸš€ ì¬ìƒì„± ì¤‘...", expanded=True)
            news_items = fetch_news(daily_kws, days=1, limit=40, strict_time=False)
            if news_items:
                status_box.write("ğŸ§  AI ë¶„ì„ ì¤‘...")
                success, result = generate_report_with_citations(api_key, news_items)
                if success:
                    save_data = {'date': target_date_str, 'report': result, 'articles': news_items}
                    save_daily_history(save_data)
                    status_box.update(label="ğŸ‰ ì™„ë£Œ!", state="complete", expanded=False)
                    st.rerun()
                else:
                    status_box.update(label="âš ï¸ ì‹¤íŒ¨", state="error")
                    st.error(result)

    if history:
        st.markdown("<div class='h-8'></div>", unsafe_allow_html=True)
        st.subheader("ğŸ—‚ï¸ ë¦¬í¬íŠ¸ ì•„ì¹´ì´ë¸Œ")
        for entry in history:
            is_today = (entry['date'] == target_date_str)
            with st.expander(f"{'ğŸ”¥ ' if is_today else ''}{entry['date']} Daily Report", expanded=is_today):
                st.markdown(f"""
                <div class="bg-white p-6 rounded-xl shadow-sm border border-gray-100 leading-relaxed text-gray-800">
                    {entry['report']}
                </div>
                """, unsafe_allow_html=True)
                st.markdown("<h4 class='text-sm font-bold text-slate-500 mt-4 mb-2'>ğŸ“š ì°¸ê³  ê¸°ì‚¬</h4>", unsafe_allow_html=True)
                for item in entry.get('articles', []):
                    st.markdown(f"<div class='flex items-start gap-2 mb-1 text-sm text-slate-600'><span class='text-blue-500 font-bold'>ğŸ“„</span><a href='{item['Link']}' target='_blank' class='hover:text-blue-600 hover:underline transition'>{item['Title']}</a></div>", unsafe_allow_html=True)

# ----------------------------------
# [Mode 2] General Category
# ----------------------------------
else:
    with st.container(border=True):
        c1, c2, c3 = st.columns([2, 1, 1])
        new_kw = c1.text_input("í‚¤ì›Œë“œ", label_visibility="collapsed")
        if c2.button("ì¶”ê°€", use_container_width=True):
            if new_kw:
                st.session_state.keywords[selected_category].append(new_kw)
                save_keywords(st.session_state.keywords)
                st.rerun()
        
        search_days = c3.slider("ê²€ìƒ‰ ê¸°ê°„", 1, 30, 3)

        if st.button("ì‹¤í–‰ (5ê°œêµ­ ê²€ìƒ‰ + ë²ˆì—­)", type="primary", use_container_width=True, disabled=not bool(api_key)):
            kws = st.session_state.keywords[selected_category]
            if kws:
                with st.spinner("ğŸŒ 5ê°œêµ­ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘..."):
                    news = fetch_news_global(api_key, kws, days=search_days)
                    st.session_state.news_data[selected_category] = news
                    st.rerun()
        
        curr_kws = st.session_state.keywords.get(selected_category, [])
        if curr_kws:
            st.write("")
            st.markdown("<div class='flex flex-wrap gap-2'>", unsafe_allow_html=True)
            cols = st.columns(8)
            for i, kw in enumerate(curr_kws):
                if cols[i%8].button(f"{kw} Ã—", key=f"gdel_{kw}"):
                    st.session_state.keywords[selected_category].remove(kw)
                    save_keywords(st.session_state.keywords)
                    st.rerun()
            st.markdown("</div>", unsafe_allow_html=True)

    data = st.session_state.news_data.get(selected_category, [])
    if data:
        st.markdown(f"<div class='text-sm text-slate-500 mb-4'>ì´ {len(data)}ê±´ ìˆ˜ì§‘ë¨ (ìµœê·¼ {search_days}ì¼)</div>", unsafe_allow_html=True)
        for item in data:
            st.markdown(f"""
            <div class="news-card">
                <div class="flex justify-between items-start">
                    <div class="text-xs font-bold text-blue-600 mb-1">{item['Source']}</div>
                    <div class="text-xs text-slate-400">{item['Date']}</div>
                </div>
                <a href="{item['Link']}" target="_blank" class="block text-base font-bold text-slate-800 hover:text-blue-600 transition decoration-0">
                    {item['Title']}
                </a>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("ìƒë‹¨ì˜ 'ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”. (API Key í•„ìš”)")
