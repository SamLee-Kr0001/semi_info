import streamlit as st
import pandas as pd
import requests
import urllib3
from urllib.parse import quote
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import json
import os
import re
import time
import yfinance as yf

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==========================================
# 0. í˜ì´ì§€ ì„¤ì • ë° ì´ˆê¸°í™” (ì˜¤ë¥˜ ë°©ì§€ í•µì‹¬)
# ==========================================
st.set_page_config(layout="wide", page_title="Semi-Insight Hub", page_icon="ğŸ’ ")

# [í•µì‹¬ ìˆ˜ì •] AttributeError ë°©ì§€ë¥¼ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ìµœìƒë‹¨ ì´ˆê¸°í™”
CATEGORIES = ["Daily Report", "ê¸°ì—…ì •ë³´", "ë°˜ë„ì²´ ì •ë³´", "Photoresist", "Wet chemical", "CMP Slurry", "Process Gas", "Wafer", "Package"]

if 'news_data' not in st.session_state:
    st.session_state.news_data = {cat: [] for cat in CATEGORIES}

if 'keywords' not in st.session_state:
    # í‚¤ì›Œë“œ ë¡œë“œ ë¡œì§ì€ ë’¤ì— í•¨ìˆ˜ë¡œ ì •ì˜ë˜ì§€ë§Œ, ì´ˆê¸°ê°’ì€ ì—¬ê¸°ì„œ ì¡ìŠµë‹ˆë‹¤.
    st.session_state.keywords = {cat: [] for cat in CATEGORIES}

if 'daily_history' not in st.session_state:
    st.session_state.daily_history = []

st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@300;400;500;600;700&display=swap');
        html, body, .stApp { font-family: 'Pretendard', sans-serif; background-color: #F8FAFC; color: #1E293B; }
        
        /* ë¦¬í¬íŠ¸ ìŠ¤íƒ€ì¼ */
        .report-box { background-color: #FFFFFF; padding: 50px; border-radius: 12px; border: 1px solid #E2E8F0; box-shadow: 0 4px 20px rgba(0,0,0,0.05); margin-bottom: 30px; line-height: 1.8; color: #334155; font-size: 16px; }
        .report-box h2 { color: #1E3A8A; border-bottom: 2px solid #3B82F6; padding-bottom: 10px; margin-top: 30px; margin-bottom: 20px; font-size: 24px; font-weight: 700; }
        
        /* ë‰´ìŠ¤ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
        .news-card { background: white; padding: 15px; border-radius: 10px; border: 1px solid #E2E8F0; margin-bottom: 10px; }
        .news-title { font-size: 16px !important; font-weight: 700 !important; color: #111827 !important; text-decoration: none; display: block; margin-bottom: 6px; }
        .news-title:hover { color: #2563EB !important; text-decoration: underline; }
        .news-meta { font-size: 12px !important; color: #94A3B8 !important; }

        /* ì‚¬ì´ë“œë°” ì£¼ì‹ í°íŠ¸ ê°•ì œ ê³ ì • */
        section[data-testid="stSidebar"] div[data-testid="stMetricValue"] { font-size: 18px !important; font-weight: 600 !important; }
        section[data-testid="stSidebar"] div[data-testid="stMetricDelta"] { font-size: 12px !important; }
        section[data-testid="stSidebar"] div[data-testid="stMetricLabel"] { font-size: 12px !important; color: #64748B !important; }
        .stock-header { font-size: 13px; font-weight: 700; color: #475569; margin-top: 15px; margin-bottom: 5px; border-bottom: 1px solid #E2E8F0; padding-bottom: 4px; }
        
        /* ë ˆí¼ëŸ°ìŠ¤ ë§í¬ ìŠ¤íƒ€ì¼ */
        .ref-link { font-size: 0.9em; color: #555; text-decoration: none; display: block; margin-bottom: 6px; padding: 5px; border-radius: 4px; transition: background 0.2s; }
        .ref-link:hover { background-color: #F1F5F9; color: #2563EB; }
        .ref-number { font-weight: bold; color: #3B82F6; margin-right: 8px; background: #DBEAFE; padding: 2px 6px; border-radius: 4px; font-size: 0.8em; }
    </style>
""", unsafe_allow_html=True)

# ê¸°ë³¸ê°’ ì„¤ì •

STOCK_CATEGORIES = {
    "ğŸ­ Chipmakers": {
        "Samsung": "005930.KS", "SK Hynix": "000660.KS", "Micron": "MU",
        "TSMC": "TSM", "Intel": "INTC", "SMIC": "0981.HK"
    },
    "ğŸ§  Fabless": {
        "Nvidia": "NVDA", "Broadcom": "AVGO", "Qnity (Q)": "Q" 
    },
    "âš™ï¸ Equipment": {
        "ASML": "ASML", "AMAT": "AMAT", "Lam Res": "LRCX", 
        "TEL": "8035.T", "KLA": "KLAC", "Hanmi": "042700.KS", "Jusung": "036930.KS"
    },
    "ğŸ§ª Materials": {
        "Shin-Etsu": "4063.T", "Sumitomo": "4005.T", "TOK": "4186.T", 
        "Nissan Chem": "4021.T", "Merck": "MRK.DE", "Air Liquide": "AI.PA", 
        "Linde": "LIN", "Soulbrain": "357780.KS", "Dongjin": "005290.KS", 
        "ENF": "102710.KS", "Ycchem": "232140.KS"
    },
    "ğŸ”‹ Others": {
        "Samsung SDI": "006400.KS"
    }
}

# ==========================================
# 1. ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜
# ==========================================
KEYWORD_FILE = 'keywords.json'
HISTORY_FILE = 'daily_history.json'

@st.cache_data(ttl=600)
def get_stock_prices_grouped():
    all_tickers = []
    for cat in STOCK_CATEGORIES.values(): all_tickers.extend(cat.values())
    ticker_str = " ".join(all_tickers)
    result_map = {}
    try:
        stocks = yf.Tickers(ticker_str)
        for symbol in all_tickers:
            try:
                hist = stocks.tickers[symbol].history(period="5d")
                if len(hist) >= 2:
                    current = hist['Close'].iloc[-1]
                    prev = hist['Close'].iloc[-2]
                    change = current - prev
                    pct = (change / prev) * 100
                    cur_sym = "â‚©" if ".KS" in symbol else ("Â¥" if ".T" in symbol else ("HK$" if ".HK" in symbol else ("â‚¬" if ".DE" in symbol or ".PA" in symbol else "$")))
                    fmt_price = f"{cur_sym}{current:,.0f}" if cur_sym in ["â‚©", "Â¥"] else f"{cur_sym}{current:,.2f}"
                    result_map[symbol] = {"Price": fmt_price, "Delta": f"{change:,.2f} ({pct:+.2f}%)"}
            except: pass
    except: pass
    return result_map

def load_keywords():
    data = {cat: [] for cat in CATEGORIES}
    if os.path.exists(KEYWORD_FILE):
        try:
            with open(KEYWORD_FILE, 'r', encoding='utf-8') as f:
                loaded = json.load(f)
            for k, v in loaded.items():
                if k in data: data[k] = v
        except: pass
    if not data.get("Daily Report"): 
        data["Daily Report"] = ["ë°˜ë„ì²´", "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤"] 
    return data

def save_keywords(data):
    try:
        with open(KEYWORD_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except: pass

def load_daily_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: return []
    return []

def save_daily_history(new_report_data):
    history = load_daily_history()
    history = [h for h in history if h['date'] != new_report_data['date']]
    history.insert(0, new_report_data)
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=4)
    except: pass

# ==========================================
# 2. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
# ==========================================
def fetch_news(keywords, days=1, limit=20, strict_time=False):
    all_items = []
    
    # ì‹œê°„ í•„í„°ë§ ê¸°ì¤€ (KST)
    now_kst = datetime.utcnow() + timedelta(hours=9)
    end_target = datetime(now_kst.year, now_kst.month, now_kst.day, 6, 0, 0)
    if now_kst.hour < 6:
        end_target -= timedelta(days=1)
    start_target = end_target - timedelta(hours=18)
    
    for kw in keywords:
        url = f"https://news.google.com/rss/search?q={quote(kw)}+when:{days}d&hl=ko&gl=KR&ceid=KR:ko"
        try:
            res = requests.get(url, timeout=5, verify=False)
            soup = BeautifulSoup(res.content, 'xml')
            items = soup.find_all('item')
            
            for item in items:
                is_valid = True
                if strict_time:
                    try:
                        pub_date_str = item.pubDate.text
                        pub_date = datetime.strptime(pub_date_str, "%a, %d %b %Y %H:%M:%S %Z")
                        pub_date_kst = pub_date + timedelta(hours=9)
                        if not (start_target <= pub_date_kst <= end_target):
                            is_valid = False
                    except: is_valid = True
                
                if is_valid:
                    all_items.append({
                        'Title': item.title.text,
                        'Link': item.link.text,
                        'Date': item.pubDate.text,
                        'Source': item.source.text if item.source else "Google News"
                    })
        except: pass
        time.sleep(0.1)
        
    df = pd.DataFrame(all_items)
    if not df.empty:
        df = df.drop_duplicates(subset=['Title'])
        return df.head(limit).to_dict('records')
    return []

# ==========================================
# 3. AI ë¦¬í¬íŠ¸ ìƒì„± (í”„ë¡¬í”„íŠ¸ ìˆ˜ì •ë¨)
# ==========================================
def get_available_models(api_key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    try:
        res = requests.get(url, timeout=10)
        if res.status_code == 200:
            data = res.json()
            return [m['name'].replace("models/", "") for m in data.get('models', []) if 'generateContent' in m.get('supportedGenerationMethods', [])]
    except: pass
    return []

def inject_links_to_report(report_text, news_data):
    """[1] -> [[1]](URL) ë³€í™˜"""
    def replace_match(match):
        try:
            idx_str = match.group(1)
            idx = int(idx_str) - 1
            if 0 <= idx < len(news_data):
                link = news_data[idx]['Link']
                return f"[[{idx_str}]]({link})"
        except: pass
        return match.group(0)
    return re.sub(r'\[(\d+)\]', replace_match, report_text)

def generate_report_with_citations(api_key, news_data):
    models = get_available_models(api_key)
    if not models:
        models = ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"]
    
    # Contextì— Source ì •ë³´ í¬í•¨
    news_context = ""
    for i, item in enumerate(news_data):
        news_context += f"[{i+1}] {item['Title']} (Source: {item['Source']})\n"

    # [ìˆ˜ì •] í”„ë¡¬í”„íŠ¸: ì„œìˆ í˜•(Narrative) ì§€ì‹œ ê°•í™”
    prompt = f"""
    ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ë°˜ë„ì²´ íˆ¬ì ë° ì „ëµ ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. 
    ì œê³µëœ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ **[ì¼ì¼ ë°˜ë„ì²´ ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ]**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

    **[ì‘ì„± ì›ì¹™ - ë§¤ìš° ì¤‘ìš”]**
    1. **ë‹¨ìˆœ ìš”ì•½ ê¸ˆì§€**: ë‰´ìŠ¤ ì œëª©ì„ ë‹¨ìˆœíˆ ë‚˜ì—´í•˜ê±°ë‚˜ ë²ˆì—­í•˜ì§€ ë§ˆì„¸ìš”.
    2. **ì„œìˆ í˜• ì‘ì„±**: ì´ìŠˆë³„ë¡œ í˜„ìƒ/ì›ì¸/ì „ë§ì„ ê°œì¡°ì‹(Bullet points)ìœ¼ë¡œ ë‚˜ëˆ„ì§€ ë§ê³ , **í•˜ë‚˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë…¼ë¦¬ì  íë¦„ì„ ê°€ì§„ ì¤„ê¸€(Narrative Paragraph)**ë¡œ ì„œìˆ í•˜ì„¸ìš”. ì „ë¬¸ì ì¸ ë¬¸ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    3. **ê·¼ê±° ëª…ì‹œ**: ëª¨ë“  ì£¼ì¥ì´ë‚˜ ì‚¬ì‹¤ ì–¸ê¸‰ ì‹œ ë°˜ë“œì‹œ ì œê³µëœ ë‰´ìŠ¤ ë²ˆí˜¸ **[1], [2]**ë¥¼ ë¬¸ì¥ ëì— ì¸ìš©í•˜ì„¸ìš”.

    [ë‰´ìŠ¤ ë°ì´í„°]
    {news_context}
    
    [ë³´ê³ ì„œ êµ¬ì¡° (Markdown)]
    ## ğŸ“Š Executive Summary (ì‹œì¥ ì´í‰)
    - ì˜¤ëŠ˜ ë°˜ë„ì²´ ì‹œì¥ì˜ í•µì‹¬ ë¶„ìœ„ê¸°ì™€ ê°€ì¥ ì¤‘ìš”í•œ ë³€í™”ë¥¼ 3~4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½. (ê¸°ì¡´ ìœ ì§€)

    ## ğŸš¨ Key Issues & Deep Dive (í•µì‹¬ ì´ìŠˆ ì‹¬ì¸µ ë¶„ì„)
    - ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ 2~3ê°€ì§€ë¥¼ ì„ ì •í•˜ì—¬ ì†Œì œëª©ì„ ë‹¬ê³  ë¶„ì„í•˜ì„¸ìš”.
    - **ì¤‘ìš”**: í˜„ìƒ, ì›ì¸, ì „ë§ì„ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•˜ì§€ ë§ê³ , **ê¹Šì´ ìˆëŠ” ì„œìˆ í˜• ë¬¸ë‹¨**ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì‚¬ê±´ì˜ ë°°ê²½ë¶€í„° íŒŒê¸‰ íš¨ê³¼ê¹Œì§€ ë§¤ë„ëŸ½ê²Œ ì—°ê²°ë˜ë„ë¡ í•˜ì„¸ìš”.
    - ë°˜ë“œì‹œ ì¸ìš© ë²ˆí˜¸[n]ë¥¼ í¬í•¨í•  ê²ƒ.

    ## ğŸ•¸ï¸ Supply Chain & Tech Trends (ê³µê¸‰ë§ ë° ê¸°ìˆ  ë™í–¥)
    - ì†Œë¶€ì¥, íŒŒìš´ë“œë¦¬, ë©”ëª¨ë¦¬ ë“± ì„¹í„°ë³„ ì£¼ìš” ë‹¨ì‹ ì„ ì¢…í•©í•˜ì—¬ ì„œìˆ .

    ## ğŸ’¡ Analyst's View (íˆ¬ì ì•„ì´ë””ì–´)
    - ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ê°€ ì£¼ëŠ” ì‹œì‚¬ì ê³¼ í–¥í›„ ê´€ì „ í¬ì¸íŠ¸ í•œ ì¤„ ì •ë¦¬.
    """
    
    headers = {'Content-Type': 'application/json'}
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
        ]
    }

    for model in models:
        if "vision" in model: continue
        
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
        try:
            response = requests.post(url, headers=headers, json=data, timeout=60)
            
            if response.status_code == 200:
                res_json = response.json()
                if 'candidates' in res_json and res_json['candidates']:
                    raw_text = res_json['candidates'][0]['content']['parts'][0]['text']
                    linked_text = inject_links_to_report(raw_text, news_data)
                    return True, linked_text
            elif response.status_code == 429:
                time.sleep(1) 
                continue
        except: continue
            
    return False, "AI ë¶„ì„ ì‹¤íŒ¨ (ëª¨ë“  ëª¨ë¸ ì‘ë‹µ ì—†ìŒ)"

# ==========================================
# 4. ë©”ì¸ ì•± UI
# ==========================================
# [ìˆ˜ì •] í‚¤ì›Œë“œ ì´ˆê¸°í™” ë¡œì§ë„ ìµœìƒë‹¨ìœ¼ë¡œ ì´ë™í–ˆì§€ë§Œ, ì•ˆì „ì„ ìœ„í•´ ì—¬ê¸°ì„œ í•œ ë²ˆ ë” ì²´í¬
if 'keywords' not in st.session_state: st.session_state.keywords = load_keywords()
# ì´ë¯¸ ìƒë‹¨ì—ì„œ news_dataë¥¼ ì´ˆê¸°í™”í–ˆìœ¼ë¯€ë¡œ AttributorErrorëŠ” í•´ê²°ë¨

with st.sidebar:
    st.header("Semi-Insight")
    st.divider()
    selected_category = st.radio("ì¹´í…Œê³ ë¦¬", CATEGORIES, index=0, label_visibility="collapsed")
    st.divider()
    
    with st.expander("ğŸ” API Key"):
        user_key = st.text_input("Key", type="password")
        if user_key: api_key = user_key
        elif "GEMINI_API_KEY" in st.secrets: api_key = st.secrets["GEMINI_API_KEY"]
        else: api_key = FALLBACK_API_KEY
    
    st.markdown("---")
    with st.expander("ğŸ“‰ Global Stock", expanded=True):
        stock_data = get_stock_prices_grouped()
        if stock_data:
            for cat, items in STOCK_CATEGORIES.items():
                st.markdown(f"<div class='stock-header'>{cat}</div>", unsafe_allow_html=True)
                for name, symbol in items.items():
                    info = stock_data.get(symbol)
                    if info:
                        c1, c2 = st.columns([1, 1.3])
                        c1.caption(f"**{name}**")
                        c2.metric("", info['Price'], info['Delta'], label_visibility="collapsed")
                        st.markdown("<hr style='margin: 2px 0; border-top: 1px dashed #f1f5f9;'>", unsafe_allow_html=True)

c_head, c_info = st.columns([3, 1])
with c_head: st.title(selected_category)

# ----------------------------------
# [Mode 1] Daily Report
# ----------------------------------
if selected_category == "Daily Report":
    # [ìˆ˜ì •] ë¬¸êµ¬ ì¶”ê°€
    st.info("â„¹ï¸ ë§¤ì¼ ì˜¤ì „ 6ì‹œ ê¸°ì¤€ ë°˜ë„ì²´ ì†Œì¬ê´€ë ¨ ì •ë³´ Report ì…ë‹ˆë‹¤.")

    now_kst = datetime.utcnow() + timedelta(hours=9)
    if now_kst.hour < 6:
        target_date = (now_kst - timedelta(days=1)).date()
    else:
        target_date = now_kst.date()
    target_date_str = target_date.strftime('%Y-%m-%d')
    
    with c_info:
        st.markdown(f"<div style='text-align:right; color:#888;'>Report Date<br><b>{target_date}</b></div>", unsafe_allow_html=True)

    with st.container(border=True):
        c1, c2 = st.columns([3, 1])
        new_kw = c1.text_input("ìˆ˜ì§‘ í‚¤ì›Œë“œ ì¶”ê°€", placeholder="ì˜ˆ: HBM, íŒ¨í‚¤ì§•", label_visibility="collapsed")
        if c2.button("ì¶”ê°€", use_container_width=True):
            if new_kw and new_kw not in st.session_state.keywords["Daily Report"]:
                st.session_state.keywords["Daily Report"].append(new_kw)
                save_keywords(st.session_state.keywords)
                st.rerun()
        
        # [ìˆ˜ì •] í‚¤ì›Œë“œ ì‹¬í”Œ ë””ìŠ¤í”Œë ˆì´ & ê²½ê³  ë¬¸êµ¬
        daily_kws = st.session_state.keywords["Daily Report"]
        if daily_kws:
            st.write("")
            cols = st.columns(len(daily_kws) if len(daily_kws) < 8 else 8)
            for i, kw in enumerate(daily_kws):
                if cols[i % 8].button(f"{kw} Ã—", key=f"del_{kw}"):
                    st.session_state.keywords["Daily Report"].remove(kw)
                    save_keywords(st.session_state.keywords)
                    st.rerun()
        
        st.caption("âš ï¸ ê´€ì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ë©´ í•´ë‹¹ ì£¼ì œë¡œ ë³´ê³ ì„œì— ë°˜ì˜ë©ë‹ˆë‹¤. ë‹¨ í‚¤ì›Œë“œê°€ ëŠ˜ì–´ë‚˜ë©´ ì‹œìŠ¤í…œ ì˜¤ë¥˜ë°œìƒ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì™¼ìª½ ê° sector ë³„ Keyword ê²€ìƒ‰ì„ í™œìš©í•´ì£¼ì„¸ìš”")
    
    history = load_daily_history()
    today_report = next((h for h in history if h['date'] == target_date_str), None)
    
    if not today_report:
        st.info(f"ğŸ“¢ {target_date} ë¦¬í¬íŠ¸ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if st.button("ğŸš€ ê¸ˆì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘", type="primary"):
            status_box = st.status("ğŸš€ ë¦¬í¬íŠ¸ ìƒì„± í”„ë¡œì„¸ìŠ¤...", expanded=True)
            
            status_box.write(f"ğŸ“¡ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ (ì „ì¼ 12:00 ~ ê¸ˆì¼ 06:00)...")
            news_items = fetch_news(daily_kws, days=2, strict_time=True)
            
            if not news_items:
                status_box.update(label="âš ï¸ ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ê°€ ì—†ì–´ ë²”ìœ„ë¥¼ í™•ì¥í•©ë‹ˆë‹¤ (ìµœê·¼ 24ì‹œê°„).", state="running")
                time.sleep(1)
                news_items = fetch_news(daily_kws, days=1, strict_time=False)
            
            if not news_items:
                status_box.update(label="âŒ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.", state="error")
            else:
                status_box.write(f"ğŸ§  AI ì‹¬ì¸µ ë¶„ì„ ì¤‘... (ê¸°ì‚¬ {len(news_items)}ê±´)")
                success, result = generate_report_with_citations(api_key, news_items)
                
                if success:
                    save_data = {'date': target_date_str, 'report': result, 'articles': news_items}
                    save_daily_history(save_data)
                    status_box.update(label="ğŸ‰ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!", state="complete")
                    st.rerun()
                else:
                    status_box.update(label="âš ï¸ AI ë¶„ì„ ì‹¤íŒ¨", state="error")
                    st.error(result)
    else:
        st.success(f"âœ… {target_date} ë¦¬í¬íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        if st.button("ğŸ”„ ë¦¬í¬íŠ¸ ë‹¤ì‹œ ë§Œë“¤ê¸° (ë®ì–´ì“°ê¸°)"):
            status_box = st.status("ğŸš€ ë¦¬í¬íŠ¸ ì¬ìƒì„± ì¤‘...", expanded=True)
            news_items = fetch_news(daily_kws, days=1, strict_time=False)
            if news_items:
                success, result = generate_report_with_citations(api_key, news_items)
                if success:
                    save_data = {'date': target_date_str, 'report': result, 'articles': news_items}
                    save_daily_history(save_data)
                    status_box.update(label="ğŸ‰ ì¬ìƒì„± ì™„ë£Œ!", state="complete")
                    st.rerun()

    if history:
        for entry in history:
            st.divider()
            st.markdown(f"<div class='history-header'>ğŸ“… {entry['date']} Daily Report</div>", unsafe_allow_html=True)
            st.markdown(f"<div class='report-box'>{entry['report']}</div>", unsafe_allow_html=True)
            
            with st.expander(f"ğŸ“š References (ê¸°ì‚¬ ì›ë¬¸) - {len(entry.get('articles', []))}ê±´"):
                st.markdown("#### ê¸°ì‚¬ ì›ë¬¸ ë§í¬")
                ref_cols = st.columns(2)
                for i, item in enumerate(entry.get('articles', [])):
                    col = ref_cols[i % 2]
                    with col:
                        st.markdown(f"""
                        <a href="{item['Link']}" target="_blank" class="ref-link">
                            <span class="ref-number">[{i+1}]</span> {item['Title']}
                        </a>
                        """, unsafe_allow_html=True)

# ----------------------------------
# [Mode 2] General Category
# ----------------------------------
else:
    with st.container(border=True):
        c1, c2, c3 = st.columns([2, 1, 1])
        new_kw = c1.text_input("í‚¤ì›Œë“œ", label_visibility="collapsed")
        if c2.button("ì¶”ê°€", use_container_width=True):
            if new_kw:
                st.session_state.keywords[selected_category].append(new_kw)
                save_keywords(st.session_state.keywords)
                st.rerun()
        if c3.button("ì‹¤í–‰", type="primary", use_container_width=True):
            kws = st.session_state.keywords[selected_category]
            if kws:
                news = fetch_news(kws, limit=20)
                st.session_state.news_data[selected_category] = news
                st.rerun()

        curr_kws = st.session_state.keywords[selected_category]
        if curr_kws:
            st.write("")
            cols = st.columns(8)
            for i, kw in enumerate(curr_kws):
                if cols[i%8].button(f"{kw} Ã—", key=f"gdel_{kw}"):
                    st.session_state.keywords[selected_category].remove(kw)
                    save_keywords(st.session_state.keywords)
                    st.rerun()

    # [ìˆ˜ì •] AttributeErrorê°€ ë°œìƒí–ˆë˜ ë¶€ë¶„ (ì´ì œ ì•ˆì „í•¨)
    data = st.session_state.news_data.get(selected_category, [])
    if data:
        st.write(f"ì´ {len(data)}ê±´ ìˆ˜ì§‘ë¨")
        for item in data:
            st.markdown(f"""
            <div class="news-card">
                <div class="news-meta">{item['Source']} | {item['Date']}</div>
                <a href="{item['Link']}" target="_blank" class="news-title">{item['Title']}</a>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("ìƒë‹¨ì˜ 'ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")
