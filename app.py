import streamlit as st
import pandas as pd
import requests
import urllib3
from urllib.parse import quote
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import json
import os
import re
import time
import yfinance as yf

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==========================================
# 0. í˜ì´ì§€ ì„¤ì • ë° ì´ˆê¸°í™”
# ==========================================
st.set_page_config(layout="wide", page_title="Semi-Insight Hub", page_icon="ğŸ’ ")

# ì¹´í…Œê³ ë¦¬ (ìš”ì²­í•˜ì‹  P&C, EDTW, PKG ë°˜ì˜)
CATEGORIES = ["Daily Report", "P&C ì†Œì¬", "EDTW ì†Œì¬", "PKG ì†Œì¬"]

# ì„¸ì…˜ ë° íŒŒì¼ ê²½ë¡œ ì„¤ì •
KEYWORD_FILE = 'keywords.json'
HISTORY_FILE = 'daily_history.json'

if 'news_data' not in st.session_state:
    st.session_state.news_data = {cat: [] for cat in CATEGORIES}

if 'daily_history' not in st.session_state:
    st.session_state.daily_history = []

st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@300;400;500;600;700&display=swap');
        html, body, .stApp { font-family: 'Pretendard', sans-serif; background-color: #F8FAFC; color: #1E293B; }
        .report-box { background-color: #FFFFFF; padding: 50px; border-radius: 12px; border: 1px solid #E2E8F0; box-shadow: 0 4px 20px rgba(0,0,0,0.05); margin-bottom: 30px; line-height: 1.8; color: #334155; font-size: 16px; }
        .report-box h2 { color: #1E3A8A; border-bottom: 2px solid #3B82F6; padding-bottom: 10px; margin-top: 30px; margin-bottom: 20px; font-size: 24px; font-weight: 700; }
        .news-card { background: white; padding: 15px; border-radius: 10px; border: 1px solid #E2E8F0; margin-bottom: 10px; }
        .news-title { font-size: 16px !important; font-weight: 700 !important; color: #111827 !important; text-decoration: none; display: block; margin-bottom: 6px; }
        .news-title:hover { color: #2563EB !important; text-decoration: underline; }
        .news-meta { font-size: 12px !important; color: #94A3B8 !important; }
        .stock-row { display: flex; justify-content: space-between; align-items: center; font-size: 14px; padding: 5px 0; border-bottom: 1px dashed #e2e8f0; }
        .stock-name { font-weight: 600; color: #334155; }
        .stock-price { font-family: 'Consolas', monospace; font-weight: 600; font-size: 14px; }
        .up-color { color: #DC2626; }
        .down-color { color: #2563EB; }
        .flat-color { color: #64748B; }
        .stock-header { font-size: 13px; font-weight: 700; color: #475569; margin-top: 15px; margin-bottom: 5px; border-bottom: 1px solid #E2E8F0; padding-bottom: 4px; }
        .ref-link { font-size: 0.9em; color: #555; text-decoration: none; display: block; margin-bottom: 6px; padding: 5px; border-radius: 4px; transition: background 0.2s; }
        .ref-link:hover { background-color: #F1F5F9; color: #2563EB; }
        .ref-number { font-weight: bold; color: #3B82F6; margin-right: 8px; background: #DBEAFE; padding: 2px 6px; border-radius: 4px; font-size: 0.8em; }
    </style>
""", unsafe_allow_html=True)

# [ì£¼ì‹ í‹°ì»¤: ì •í™•ë„ ê°œì„  ë²„ì „ ìœ ì§€]
STOCK_CATEGORIES = {
    "ğŸ­ Chipmakers": {"Samsung": "005930.KS", "SK Hynix": "000660.KS", "Micron": "MU", "TSMC": "TSM", "Intel": "INTC", "SMIC": "0981.HK"},
    "ğŸ§  Fabless": {"Nvidia": "NVDA", "Broadcom": "AVGO", "Qnity (Q)": "Q"},
    "ğŸ§ª Materials": {"Soulbrain": "357780.KQ", "Dongjin": "005290.KQ", "Hana Mat": "166090.KQ", "Wonik Mat": "104830.KQ", "TCK": "064760.KQ", "Foosung": "093370.KS", "PI Adv": "178920.KS", "ENF": "102710.KQ", "TEMC": "425040.KQ", "YC Chem": "112290.KQ", "Samsung SDI": "006400.KS", "Shin-Etsu": "4063.T", "Sumco": "3436.T", "Merck": "MRK.DE", "Entegris": "ENTG", "TOK": "4186.T", "Resonac": "4004.T", "Air Prod": "APD", "Linde": "LIN", "Qnity": "Q", "Nissan Chem": "4021.T", "Sumitomo": "4005.T"},
    "âš™ï¸ Equipment": {"ASML": "ASML", "AMAT": "AMAT", "Lam Res": "LRCX", "TEL": "8035.T", "KLA": "KLAC", "Advantest": "6857.T", "Hitachi HT": "8036.T", "Hanmi": "042700.KS", "Wonik IPS": "240810.KQ", "Jusung": "036930.KQ", "EO Tech": "039030.KQ", "Techwing": "089030.KQ", "Eugene": "084370.KQ", "PSK": "319660.KQ", "Zeus": "079370.KQ", "Top Eng": "065130.KQ"}
}

# ==========================================
# 1. ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜ (ì €ì¥ ê¸°ëŠ¥ ê°•í™”)
# ==========================================
def load_keywords():
    data = {cat: [] for cat in CATEGORIES}
    if os.path.exists(KEYWORD_FILE):
        try:
            with open(KEYWORD_FILE, 'r', encoding='utf-8') as f:
                loaded = json.load(f)
            for k, v in loaded.items():
                if k in data: data[k] = v
        except: pass
    if not data.get("Daily Report"): 
        data["Daily Report"] = ["ë°˜ë„ì²´", "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤"] 
    return data

def save_keywords(data):
    try:
        with open(KEYWORD_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except: pass

def load_daily_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: return []
    return []

def save_daily_history(new_report_data):
    history = load_daily_history()
    # ë‚ ì§œ ì¤‘ë³µ ì‹œ ë®ì–´ì“°ê¸°
    history = [h for h in history if h['date'] != new_report_data['date']]
    history.insert(0, new_report_data) # ìµœì‹ ìˆœ ì €ì¥
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=4)
    except: pass

# í‚¤ì›Œë“œ ì´ˆê¸° ë¡œë“œ
if 'keywords' not in st.session_state or not st.session_state.keywords.get("Daily Report"):
    st.session_state.keywords = load_keywords()

@st.cache_data(ttl=300)
def get_stock_prices_grouped():
    result_map = {}
    for cat, items in STOCK_CATEGORIES.items():
        for name, symbol in items.items():
            try:
                ticker = yf.Ticker(symbol)
                try: 
                    current = ticker.fast_info['last_price']
                    prev = ticker.fast_info['previous_close']
                except:
                    try:
                        hist = ticker.history(period="1d", interval="1m")
                        if not hist.empty:
                            current = hist['Close'].iloc[-1]
                            prev = ticker.info.get('previousClose', current)
                        else: raise ValueError
                    except:
                        hist = ticker.history(period="5d")
                        if len(hist) >= 2:
                            current = hist['Close'].iloc[-1]
                            prev = hist['Close'].iloc[-2]
                        else: continue

                change = current - prev
                pct = (change / prev) * 100
                
                if ".KS" in symbol or ".KQ" in symbol: cur_sym = "â‚©"
                elif ".T" in symbol: cur_sym = "Â¥"
                elif ".HK" in symbol: cur_sym = "HK$"
                elif ".DE" in symbol: cur_sym = "â‚¬"
                else: cur_sym = "$"
                
                fmt_price = f"{cur_sym}{current:,.0f}" if cur_sym in ["â‚©", "Â¥"] else f"{cur_sym}{current:,.2f}"
                
                if change > 0: color_class, arrow, sign = "up-color", "â–²", "+"
                elif change < 0: color_class, arrow, sign = "down-color", "â–¼", ""
                else: color_class, arrow, sign = "flat-color", "-", ""
                
                html_str = f"""<div class="stock-row"><span class="stock-name">{name}</span><span class="stock-price {color_class}">{fmt_price} <span style="font-size:0.9em; margin-left:3px;">{arrow} {sign}{pct:.2f}%</span></span></div>"""
                result_map[name] = html_str
            except Exception: pass
    return result_map

# ==========================================
# 2. ë‰´ìŠ¤ ìˆ˜ì§‘ (ì§€ë‚œì£¼ ê¸ˆìš”ì¼ ë¡œì§ 100% ë™ì¼ - ì•ˆì •ì„± í™•ë³´)
# ==========================================
def fetch_news(keywords, days=1, limit=20, strict_time=False):
    all_items = []
    
    now_kst = datetime.utcnow() + timedelta(hours=9)
    end_target = datetime(now_kst.year, now_kst.month, now_kst.day, 6, 0, 0)
    if now_kst.hour < 6:
        end_target -= timedelta(days=1)
    start_target = end_target - timedelta(hours=18)
    
    for kw in keywords:
        url = f"https://news.google.com/rss/search?q={quote(kw)}+when:{days}d&hl=ko&gl=KR&ceid=KR:ko"
        try:
            res = requests.get(url, timeout=5, verify=False)
            soup = BeautifulSoup(res.content, 'xml')
            items = soup.find_all('item')
            
            for item in items:
                is_valid = True
                if strict_time:
                    try:
                        pub_date_str = item.pubDate.text
                        pub_date = datetime.strptime(pub_date_str, "%a, %d %b %Y %H:%M:%S %Z")
                        pub_date_kst = pub_date + timedelta(hours=9)
                        if not (start_target <= pub_date_kst <= end_target):
                            is_valid = False
                    except: is_valid = True
                
                if is_valid:
                    all_items.append({
                        'Title': item.title.text,
                        'Link': item.link.text,
                        'Date': item.pubDate.text,
                        'Source': item.source.text if item.source else "Google News"
                    })
        except: pass
        time.sleep(0.1)
        
    df = pd.DataFrame(all_items)
    if not df.empty:
        df = df.drop_duplicates(subset=['Title'])
        return df.head(limit).to_dict('records')
    return []

# ==========================================
# 3. AI ë¦¬í¬íŠ¸ ìƒì„± (ì§€ë‚œì£¼ ê¸ˆìš”ì¼ ë¡œì§ 100% ë™ì¼)
# ==========================================
def get_available_models(api_key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    try:
        res = requests.get(url, timeout=10)
        if res.status_code == 200:
            data = res.json()
            return [m['name'].replace("models/", "") for m in data.get('models', []) if 'generateContent' in m.get('supportedGenerationMethods', [])]
    except: pass
    return []

def inject_links_to_report(report_text, news_data):
    def replace_match(match):
        try:
            idx_str = match.group(1)
            idx = int(idx_str) - 1
            if 0 <= idx < len(news_data):
                link = news_data[idx]['Link']
                return f"[[{idx_str}]]({link})"
        except: pass
        return match.group(0)
    return re.sub(r'\[(\d+)\]', replace_match, report_text)

def generate_report_with_citations(api_key, news_data):
    models = get_available_models(api_key)
    if not models:
        models = ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"]
    
    news_context = ""
    for i, item in enumerate(news_data):
        news_context += f"[{i+1}] {item['Title']} (Source: {item['Source']})\n"

    prompt = f"""
    ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ë°˜ë„ì²´ íˆ¬ì ë° ì „ëµ ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. 
    ì œê³µëœ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ **[ì¼ì¼ ë°˜ë„ì²´ì™€ ë°˜ë„ì²´ ì†Œì¬ ê´€ë ¨í•œ ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ]**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

    **[ì‘ì„± ì›ì¹™ - ë§¤ìš° ì¤‘ìš”]**
    1. **ë‹¨ìˆœ ìš”ì•½ ê¸ˆì§€**: ë‰´ìŠ¤ ì œëª©ì„ ë‹¨ìˆœíˆ ë‚˜ì—´í•˜ê±°ë‚˜ ë²ˆì—­í•˜ì§€ ë§ˆì„¸ìš”.
    2. **ì„œìˆ í˜• ì‘ì„±**: ì´ìŠˆë³„ë¡œ í˜„ìƒ/ì›ì¸/ì „ë§ì„ ê°œì¡°ì‹(Bullet points)ìœ¼ë¡œ ë‚˜ëˆ„ì§€ ë§ê³ , **í•˜ë‚˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë…¼ë¦¬ì  íë¦„ì„ ê°€ì§„ ì¤„ê¸€(Narrative Paragraph)**ë¡œ ì„œìˆ í•˜ì„¸ìš”. ì „ë¬¸ì ì¸ ë¬¸ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    3. **ê·¼ê±° ëª…ì‹œ**: ëª¨ë“  ì£¼ì¥ì´ë‚˜ ì‚¬ì‹¤ ì–¸ê¸‰ ì‹œ ë°˜ë“œì‹œ ì œê³µëœ ë‰´ìŠ¤ ë²ˆí˜¸ **[1], [2]**ë¥¼ ë¬¸ì¥ ëì— ì¸ìš©í•˜ì„¸ìš”.

    [ë‰´ìŠ¤ ë°ì´í„°]
    {news_context}
    
    [ë³´ê³ ì„œ êµ¬ì¡° (Markdown)]
    ## ğŸ“Š Executive Summary (ì‹œì¥ ì´í‰)
    - ì˜¤ëŠ˜ ë°˜ë„ì²´ ì‹œì¥ì˜ í•µì‹¬ ë¶„ìœ„ê¸°ì™€ ê°€ì¥ ì¤‘ìš”í•œ ë³€í™”ë¥¼ 3~4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½.

    ## ğŸš¨ Key Issues & Deep Dive (í•µì‹¬ ì´ìŠˆ ì‹¬ì¸µ ë¶„ì„)
    - ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ 2~3ê°€ì§€ë¥¼ ì„ ì •í•˜ì—¬ ì†Œì œëª©ì„ ë‹¬ê³  ë¶„ì„í•˜ì„¸ìš”.
    - **ì¤‘ìš”**: í˜„ìƒ, ì›ì¸, ì „ë§ì„ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•˜ì§€ ë§ê³ , **ê¹Šì´ ìˆëŠ” ì„œìˆ í˜• ë¬¸ë‹¨**ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì‚¬ê±´ì˜ ë°°ê²½ë¶€í„° íŒŒê¸‰ íš¨ê³¼ê¹Œì§€ ë§¤ë„ëŸ½ê²Œ ì—°ê²°ë˜ë„ë¡ í•˜ì„¸ìš”.
    - ë°˜ë“œì‹œ ì¸ìš© ë²ˆí˜¸[n]ë¥¼ í¬í•¨í•  ê²ƒ.

    ## ğŸ•¸ï¸ Supply Chain & Tech Trends (ê³µê¸‰ë§ ë° ê¸°ìˆ  ë™í–¥)
    - ë°˜ë„ì²´ ì†Œì¬ ê·¸ë¦¬ê³  ì†Œë¶€ì¥, íŒŒìš´ë“œë¦¬, ë©”ëª¨ë¦¬ ë“± ì„¹í„°ë³„ ì£¼ìš” ë‹¨ì‹ ì„ ì¢…í•©í•˜ì—¬ ì„œìˆ .

    ## ğŸ’¡ Analyst's View (íˆ¬ì ì•„ì´ë””ì–´)
    - ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ê°€ ì£¼ëŠ” ì‹œì‚¬ì ê³¼ í–¥í›„ ê´€ì „ í¬ì¸íŠ¸ í•œ ì¤„ ì •ë¦¬.
    """
    
    headers = {'Content-Type': 'application/json'}
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [{"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"}]
    }

    for model in models:
        if "vision" in model: continue
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
        try:
            response = requests.post(url, headers=headers, json=data, timeout=60)
            if response.status_code == 200:
                res_json = response.json()
                if 'candidates' in res_json and res_json['candidates']:
                    raw_text = res_json['candidates'][0]['content']['parts'][0]['text']
                    return True, inject_links_to_report(raw_text, news_data)
            elif response.status_code == 429:
                time.sleep(1) 
                continue
        except: continue
            
    return False, "AI ë¶„ì„ ì‹¤íŒ¨ (ëª¨ë“  ëª¨ë¸ ì‘ë‹µ ì—†ìŒ)"

# ==========================================
# 4. ë©”ì¸ ì•± UI
# ==========================================
with st.sidebar:
    st.header("Semi-Insight")
    st.divider()
    selected_category = st.radio("ì¹´í…Œê³ ë¦¬", CATEGORIES, index=0, label_visibility="collapsed")
    st.divider()
    
    with st.expander("ğŸ” API Key"):
        user_key = st.text_input("Key", type="password")
        if user_key: api_key = user_key
        elif "GEMINI_API_KEY" in st.secrets: api_key = st.secrets["GEMINI_API_KEY"]
        else: api_key = ""
    
    st.markdown("---")
    with st.expander("ğŸ“‰ Global Stock", expanded=True):
        if st.button("ğŸ”„ ì‹œì„¸ ì—…ë°ì´íŠ¸", use_container_width=True):
            get_stock_prices_grouped.clear()
            st.rerun()
        stock_data = get_stock_prices_grouped()
        if stock_data:
            for cat, items in STOCK_CATEGORIES.items():
                st.markdown(f"<div class='stock-header'>{cat}</div>", unsafe_allow_html=True)
                for name, symbol in items.items():
                    html_info = stock_data.get(name)
                    if html_info: st.markdown(html_info, unsafe_allow_html=True)
    st.caption("â„¹ï¸ 'ì‹œì„¸ ì—…ë°ì´íŠ¸' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ìµœì‹ ê°€ë¡œ ê°±ì‹ ë©ë‹ˆë‹¤.")

c_head, c_info = st.columns([3, 1])
with c_head: st.title(selected_category)

# ----------------------------------
# [Mode 1] Daily Report
# ----------------------------------
if selected_category == "Daily Report":
    st.info("â„¹ï¸ ë§¤ì¼ ì˜¤ì „ 6ì‹œ ê¸°ì¤€ ë°˜ë„ì²´ ì†Œì¬ê´€ë ¨ ì •ë³´ Report ì…ë‹ˆë‹¤.")
    now_kst = datetime.utcnow() + timedelta(hours=9)
    if now_kst.hour < 6:
        target_date = (now_kst - timedelta(days=1)).date()
    else:
        target_date = now_kst.date()
    target_date_str = target_date.strftime('%Y-%m-%d')
    
    with c_info: st.markdown(f"<div style='text-align:right; color:#888;'>Report Date<br><b>{target_date}</b></div>", unsafe_allow_html=True)

    # [í‚¤ì›Œë“œ ê´€ë¦¬ + ì¦‰ì‹œ ì €ì¥ ê¸°ëŠ¥]
    with st.container(border=True):
        c1, c2 = st.columns([3, 1])
        new_kw = c1.text_input("ìˆ˜ì§‘ í‚¤ì›Œë“œ ì¶”ê°€", placeholder="ì˜ˆ: HBM, íŒ¨í‚¤ì§•", label_visibility="collapsed")
        if c2.button("ì¶”ê°€", use_container_width=True):
            if new_kw and new_kw not in st.session_state.keywords["Daily Report"]:
                st.session_state.keywords["Daily Report"].append(new_kw)
                save_keywords(st.session_state.keywords) # ì €ì¥ í•„ìˆ˜
                st.rerun()
        
        daily_kws = st.session_state.keywords["Daily Report"]
        if daily_kws:
            st.write("")
            cols = st.columns(len(daily_kws) if len(daily_kws) < 8 else 8)
            for i, kw in enumerate(daily_kws):
                if cols[i % 8].button(f"{kw} Ã—", key=f"del_{kw}"):
                    st.session_state.keywords["Daily Report"].remove(kw)
                    save_keywords(st.session_state.keywords) # ì €ì¥ í•„ìˆ˜
                    st.rerun()
        st.caption("âš ï¸ ê´€ì‹¬ í‚¤ì›Œë“œëŠ” ìë™ ì €ì¥ ë©ë‹ˆë‹¤. í‚¤ì›Œë“œê°€ ë§ì•„ì§ˆìˆ˜ë¡ ì˜¤ë¥˜ë°œìƒ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì™¼í¸ì˜ sectionë³„ news crawling ë©”ë‰´ë¥¼ í™œìš©í•˜ì„¸ìš”.")
    
    # [ë¦¬í¬íŠ¸ íˆìŠ¤í† ë¦¬ ë¡œë“œ]
    history = load_daily_history()
    today_report = next((h for h in history if h['date'] == target_date_str), None)
    
    if not today_report:
        st.info(f"ğŸ“¢ {target_date} ë¦¬í¬íŠ¸ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if st.button("ğŸš€ ê¸ˆì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘", type="primary"):
            status_box = st.status("ğŸš€ ë¦¬í¬íŠ¸ ìƒì„± í”„ë¡œì„¸ìŠ¤...", expanded=True)
            status_box.write(f"ğŸ“¡ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ (ì „ì¼ 12:00 ~ ê¸ˆì¼ 06:00)...")
            news_items = fetch_news(daily_kws, days=2, strict_time=True)
            
            if not news_items:
                status_box.update(label="âš ï¸ ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ê°€ ì—†ì–´ ë²”ìœ„ë¥¼ í™•ì¥í•©ë‹ˆë‹¤ (ìµœê·¼ 24ì‹œê°„).", state="running")
                time.sleep(1)
                news_items = fetch_news(daily_kws, days=1, strict_time=False)
            
            if not news_items:
                status_box.update(label="âŒ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.", state="error")
            else:
                status_box.write(f"ğŸ§  AI ì‹¬ì¸µ ë¶„ì„ ì¤‘... (ê¸°ì‚¬ {len(news_items)}ê±´)")
                success, result = generate_report_with_citations(api_key, news_items)
                if success:
                    save_data = {'date': target_date_str, 'report': result, 'articles': news_items}
                    save_daily_history(save_data) # [ë¦¬í¬íŠ¸ ì €ì¥]
                    status_box.update(label="ğŸ‰ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!", state="complete")
                    st.rerun()
                else:
                    status_box.update(label="âš ï¸ AI ë¶„ì„ ì‹¤íŒ¨", state="error")
                    st.error(result)
    else:
        st.success(f"âœ… {target_date} ë¦¬í¬íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        if st.button("ğŸ”„ ë¦¬í¬íŠ¸ ë‹¤ì‹œ ë§Œë“¤ê¸° (ë®ì–´ì“°ê¸°)"):
            status_box = st.status("ğŸš€ ë¦¬í¬íŠ¸ ì¬ìƒì„± ì¤‘...", expanded=True)
            news_items = fetch_news(daily_kws, days=1, strict_time=False)
            if news_items:
                success, result = generate_report_with_citations(api_key, news_items)
                if success:
                    save_data = {'date': target_date_str, 'report': result, 'articles': news_items}
                    save_daily_history(save_data) # [ë¦¬í¬íŠ¸ ì €ì¥]
                    status_box.update(label="ğŸ‰ ì¬ìƒì„± ì™„ë£Œ!", state="complete")
                    st.rerun()

    # [ë¦¬í¬íŠ¸ í•˜ë‹¨ ì €ì¥ ë° í‘œì‹œ (Expander ë°©ì‹)]
    if history:
        st.markdown("---")
        st.subheader("ğŸ—‚ï¸ ì§€ë‚œ ë¦¬í¬íŠ¸ ê¸°ë¡")
        for entry in history:
            # ì˜¤ëŠ˜ ë‚ ì§œëŠ” ê¸°ë³¸ í¼ì¹¨, ê³¼ê±° ë‚ ì§œëŠ” ì ‘í˜
            is_expanded = (entry['date'] == target_date_str)
            with st.expander(f"ğŸ“… {entry['date']} Daily Report", expanded=is_expanded):
                st.markdown(f"<div class='report-box'>{entry['report']}</div>", unsafe_allow_html=True)
                st.markdown("#### ğŸ“š ê¸°ì‚¬ ì›ë¬¸ ë§í¬")
                ref_cols = st.columns(2)
                for i, item in enumerate(entry.get('articles', [])):
                    col = ref_cols[i % 2]
                    with col:
                        st.markdown(f"""<a href="{item['Link']}" target="_blank" class="ref-link"><span class="ref-number">[{i+1}]</span> {item['Title']}</a>""", unsafe_allow_html=True)

# ----------------------------------
# [Mode 2] General Category (P&C, EDTW, PKG)
# ----------------------------------
else:
    with st.container(border=True):
        c1, c2, c3 = st.columns([2, 1, 1])
        new_kw = c1.text_input("í‚¤ì›Œë“œ", label_visibility="collapsed")
        if c2.button("ì¶”ê°€", use_container_width=True):
            if new_kw:
                st.session_state.keywords[selected_category].append(new_kw)
                save_keywords(st.session_state.keywords)
                st.rerun()
        if c3.button("ì‹¤í–‰", type="primary", use_container_width=True):
            kws = st.session_state.keywords[selected_category]
            if kws:
                news = fetch_news(kws, limit=20)
                st.session_state.news_data[selected_category] = news
                st.rerun()
        curr_kws = st.session_state.keywords.get(selected_category, [])
        if curr_kws:
            st.write("")
            cols = st.columns(8)
            for i, kw in enumerate(curr_kws):
                if cols[i%8].button(f"{kw} Ã—", key=f"gdel_{kw}"):
                    st.session_state.keywords[selected_category].remove(kw)
                    save_keywords(st.session_state.keywords)
                    st.rerun()
    
    data = st.session_state.news_data.get(selected_category, [])
    if data:
        st.write(f"ì´ {len(data)}ê±´ ìˆ˜ì§‘ë¨")
        for item in data:
            st.markdown(f"""<div class="news-card"><div class="news-meta">{item['Source']} | {item['Date']}</div><a href="{item['Link']}" target="_blank" class="news-title" style="text-decoration:none;">{item['Title']}</a></div>""", unsafe_allow_html=True)
    else:
        st.info("ìƒë‹¨ì˜ 'ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")
