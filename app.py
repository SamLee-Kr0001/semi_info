import streamlit as st
import pandas as pd
import requests
import urllib3
from urllib.parse import quote
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import json
import os
import re
import time
import yfinance as yf

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==========================================
# 0. í˜ì´ì§€ ì„¤ì • ë° ìŠ¤íƒ€ì¼
# ==========================================
st.set_page_config(layout="wide", page_title="Semi-Insight Hub", page_icon="ğŸ’ ")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (AttributeError ë°©ì§€)
CATEGORIES = ["Daily Report", "ê¸°ì—…ì •ë³´", "ë°˜ë„ì²´ ì •ë³´", "Photoresist", "Wet chemical", "CMP Slurry", "Process Gas", "Wafer", "Package"]

if 'news_data' not in st.session_state:
    st.session_state.news_data = {cat: [] for cat in CATEGORIES}

st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@300;400;500;600;700&display=swap');
        html, body, .stApp { font-family: 'Pretendard', sans-serif; background-color: #F8FAFC; color: #1E293B; }
        
        .report-box { background-color: #FFFFFF; padding: 50px; border-radius: 12px; border: 1px solid #E2E8F0; box-shadow: 0 4px 20px rgba(0,0,0,0.05); margin-bottom: 30px; line-height: 1.8; color: #334155; font-size: 16px; }
        .report-box h2 { color: #1E3A8A; border-bottom: 2px solid #3B82F6; padding-bottom: 10px; margin-top: 30px; margin-bottom: 20px; font-size: 24px; font-weight: 700; }
        
        .news-card { background: white; padding: 15px; border-radius: 10px; border: 1px solid #E2E8F0; margin-bottom: 10px; }
        .news-title { font-size: 16px !important; font-weight: 700 !important; color: #111827 !important; text-decoration: none; display: block; margin-bottom: 6px; }
        .news-title:hover { color: #2563EB !important; text-decoration: underline; }
        .news-meta { font-size: 12px !important; color: #94A3B8 !important; }

        section[data-testid="stSidebar"] div[data-testid="stMetricValue"] { font-size: 18px !important; font-weight: 600 !important; }
        section[data-testid="stSidebar"] div[data-testid="stMetricDelta"] { font-size: 12px !important; }
        section[data-testid="stSidebar"] div[data-testid="stMetricLabel"] { font-size: 12px !important; color: #64748B !important; }
        .stock-header { font-size: 13px; font-weight: 700; color: #475569; margin-top: 15px; margin-bottom: 5px; border-bottom: 1px solid #E2E8F0; padding-bottom: 4px; }
        
        .ref-link { font-size: 0.9em; color: #555; text-decoration: none; display: block; margin-bottom: 6px; padding: 5px; border-radius: 4px; transition: background 0.2s; }
        .ref-link:hover { background-color: #F1F5F9; color: #2563EB; }
        .ref-number { font-weight: bold; color: #3B82F6; margin-right: 8px; background: #DBEAFE; padding: 2px 6px; border-radius: 4px; font-size: 0.8em; }
    </style>
""", unsafe_allow_html=True)

FALLBACK_API_KEY = "AIzaSyCBSqIQBIYQbWtfQAxZ7D5mwCKFx-7VDJo"

STOCK_CATEGORIES = {
    "ğŸ­ Chipmakers": {"Samsung": "005930.KS", "SK Hynix": "000660.KS", "Micron": "MU", "TSMC": "TSM", "Intel": "INTC", "SMIC": "0981.HK"},
    "ğŸ§  Fabless": {"Nvidia": "NVDA", "Broadcom": "AVGO", "Qnity (Q)": "Q"},
    "âš™ï¸ Equipment": {"ASML": "ASML", "AMAT": "AMAT", "Lam Res": "LRCX", "TEL": "8035.T", "KLA": "KLAC", "Hanmi": "042700.KS", "Jusung": "036930.KS"},
    "ğŸ§ª Materials": {"Shin-Etsu": "4063.T", "Sumitomo": "4005.T", "TOK": "4186.T", "Nissan Chem": "4021.T", "Merck": "MRK.DE", "Air Liquide": "AI.PA", "Linde": "LIN", "Soulbrain": "357780.KS", "Dongjin": "005290.KS", "ENF": "102710.KS", "Ycchem": "232140.KS"},
    "ğŸ”‹ Others": {"Samsung SDI": "006400.KS"}
}

KEYWORD_FILE = 'keywords.json'
HISTORY_FILE = 'daily_history.json'

# ==========================================
# 1. ë°ì´í„° ê´€ë¦¬ (ë¬¸ë²• ì˜¤ë¥˜ ìˆ˜ì •ë¨)
# ==========================================
def load_keywords():
    data = {cat: [] for cat in CATEGORIES}
    
    # 1ìˆœìœ„: ì €ì¥ëœ íŒŒì¼ ì½ê¸°
    if os.path.exists(KEYWORD_FILE):
        try:
            with open(KEYWORD_FILE, 'r', encoding='utf-8') as f:
                loaded = json.load(f)
            for k, v in loaded.items():
                if k in data: 
                    data[k] = v
        except: pass
    
    # 2ìˆœìœ„: ê¸°ë³¸ê°’
    if not data.get("Daily Report"): 
        data["Daily Report"] = ["ë°˜ë„ì²´", "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤"] 
        
    return data

def save_keywords(data):
    try:
        with open(KEYWORD_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except: pass

def load_daily_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: return []
    return []

def save_daily_history(new_report_data):
    history = load_daily_history()
    history = [h for h in history if h['date'] != new_report_data['date']]
    history.insert(0, new_report_data)
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=4)
    except: pass

@st.cache_data(ttl=600)
def get_stock_prices_grouped():
    all_tickers = []
    for cat in STOCK_CATEGORIES.values(): all_tickers.extend(cat.values())
    ticker_str = " ".join(all_tickers)
    result_map = {}
    try:
        stocks = yf.Tickers(ticker_str)
        for symbol in all_tickers:
            try:
                hist = stocks.tickers[symbol].history(period="5d")
                if len(hist) >= 2:
                    current = hist['Close'].iloc[-1]
                    prev = hist['Close'].iloc[-2]
                    change = current - prev
                    pct = (change / prev) * 100
                    cur_sym = "â‚©" if ".KS" in symbol else ("Â¥" if ".T" in symbol else ("HK$" if ".HK" in symbol else ("â‚¬" if ".DE" in symbol or ".PA" in symbol else "$")))
                    fmt_price = f"{cur_sym}{current:,.0f}" if cur_sym in ["â‚©", "Â¥"] else f"{cur_sym}{current:,.2f}"
                    result_map[symbol] = {"Price": fmt_price, "Delta": f"{change:,.2f} ({pct:+.2f}%)"}
            except: pass
    except: pass
    return result_map

# ==========================================
# 2. ë‰´ìŠ¤ ìˆ˜ì§‘
# ==========================================
def fetch_news_strict_window(keywords, target_date, limit=20):
    all_items = []
    
    # KST ê¸°ì¤€ ì‹œê°„ ì„¤ì •
    end_dt = datetime.combine(target_date, datetime.min.time()) + timedelta(hours=6) # ë‹¹ì¼ 06:00
    start_dt = end_dt - timedelta(hours=18) # ì „ì¼ 12:00
    
    search_days = 2 
    
    for kw in keywords:
        url = f"https://news.google.com/rss/search?q={quote(kw)}+when:{search_days}d&hl=ko&gl=KR&ceid=KR:ko"
        try:
            res = requests.get(url, timeout=5, verify=False)
            soup = BeautifulSoup(res.content, 'xml')
            items = soup.find_all('item')
            
            for item in items:
                try:
                    pub_date_str = item.pubDate.text
                    pub_date_gmt = datetime.strptime(pub_date_str, "%a, %d %b %Y %H:%M:%S %Z")
                    pub_date_kst = pub_date_gmt + timedelta(hours=9)
                    
                    if start_dt <= pub_date_kst <= end_dt:
                        all_items.append({
                            'Title': item.title.text,
                            'Link': item.link.text,
                            'Date': pub_date_str,
                            'Source': item.source.text if item.source else "Google News",
                            'Timestamp': pub_date_kst
                        })
                except: continue
        except: pass
        time.sleep(0.1)
        
    df = pd.DataFrame(all_items)
    if not df.empty:
        df = df.sort_values(by='Timestamp', ascending=False)
        df = df.drop_duplicates(subset=['Title'])
        return df.head(limit).to_dict('records')
    return []

# ==========================================
# 3. AI ë¶„ì„
# ==========================================
def get_available_models(api_key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    try:
        res = requests.get(url, timeout=10)
        if res.status_code == 200:
            data = res.json()
            return [m['name'].replace("models/", "") for m in data.get('models', []) if 'generateContent' in m.get('supportedGenerationMethods', [])]
    except: pass
    return []

def inject_links_to_report(report_text, news_data):
    def replace_match(match):
        try:
            idx = int(match.group(1)) - 1
            if 0 <= idx < len(news_data):
                return f"[[{match.group(1)}]]({news_data[idx]['Link']})"
        except: pass
        return match.group(0)
    return re.sub(r'\[(\d+)\]', replace_match, report_text)

def generate_report(api_key, news_data):
    models = get_available_models(api_key)
    if not models: models = ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"]
    
    news_context = ""
    for i, item in enumerate(news_data):
        news_context += f"[{i+1}] {item['Title']} (Source: {item['Source']})\n"

    prompt = f"""
    ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ë°˜ë„ì²´ íˆ¬ì ë° ì „ëµ ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. 
    ì œê³µëœ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ **[ì¼ì¼ ë°˜ë„ì²´ ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ]**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

    **[ì‘ì„± ì›ì¹™]**
    1. **ì„œìˆ í˜• ì‘ì„±**: ì´ìŠˆë³„ë¡œ í˜„ìƒ/ì›ì¸/ì „ë§ì„ ë‚˜ëˆ„ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ¬ìš´ ë…¼ë¦¬ì  íë¦„(Narrative)ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”.
    2. **ê·¼ê±° ëª…ì‹œ**: ë‚´ìš©ì˜ ì¶œì²˜ê°€ ë˜ëŠ” ë‰´ìŠ¤ ë²ˆí˜¸ **[1], [2]**ë¥¼ ë¬¸ì¥ ëì— ë°˜ë“œì‹œ ì¸ìš©í•˜ì„¸ìš”.
    3. **ì „ë¬¸ì  ì–´ì¡°**: íˆ¬ìì ë¦¬í¬íŠ¸ í†¤ì•¤ë§¤ë„ˆë¥¼ ìœ ì§€í•˜ì„¸ìš”.

    [ë‰´ìŠ¤ ë°ì´í„°]
    {news_context}
    
    [ë³´ê³ ì„œ êµ¬ì¡° (Markdown)]
    ## ğŸ“Š Executive Summary (ì‹œì¥ ì´í‰)
    - ì˜¤ëŠ˜ ë°˜ë„ì²´ ì‹œì¥ì˜ í•µì‹¬ ë¶„ìœ„ê¸°ì™€ ê°€ì¥ ì¤‘ìš”í•œ ë³€í™” ìš”ì•½.

    ## ğŸš¨ Key Issues & Deep Dive (í•µì‹¬ ì´ìŠˆ ì‹¬ì¸µ ë¶„ì„)
    - ì¤‘ìš” ì´ìŠˆ 2~3ê°€ì§€ë¥¼ ì„ ì •í•˜ì—¬ ì†Œì œëª©ì„ ë‹¬ê³  ë¶„ì„.
    - ë°°ê²½, ì›ì¸, íŒŒê¸‰ íš¨ê³¼ë¥¼ ì—°ê²°í•˜ì—¬ ê¹Šì´ ìˆê²Œ ì„œìˆ .

    ## ğŸ•¸ï¸ Supply Chain & Tech Trends (ê³µê¸‰ë§ ë° ê¸°ìˆ  ë™í–¥)
    - ì†Œë¶€ì¥, íŒŒìš´ë“œë¦¬, ë©”ëª¨ë¦¬ ë“± ì„¹í„°ë³„ ì£¼ìš” ë‹¨ì‹  ì¢…í•©.

    ## ğŸ’¡ Analyst's View (íˆ¬ì ì•„ì´ë””ì–´)
    - ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ê°€ ì£¼ëŠ” ì‹œì‚¬ì ê³¼ í–¥í›„ ê´€ì „ í¬ì¸íŠ¸.
    """
    
    headers = {'Content-Type': 'application/json'}
    data = {"contents": [{"parts": [{"text": prompt}]}], "safetySettings": [{"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"}]}

    for model in models:
        if "vision" in model: continue
        try:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
            response = requests.post(url, headers=headers, json=data, timeout=60)
            if response.status_code == 200:
                raw_text = response.json()['candidates'][0]['content']['parts'][0]['text']
                return True, inject_links_to_report(raw_text, news_data)
            elif response.status_code == 429:
                time.sleep(1)
                continue
        except: continue
            
    return False, "AI ë¶„ì„ ì‹¤íŒ¨ (ëª¨ë“  ëª¨ë¸ ì‘ë‹µ ì—†ìŒ)"

# ==========================================
# 4. ë©”ì¸ UI
# ==========================================
if 'keywords' not in st.session_state: 
    st.session_state.keywords = load_keywords()

with st.sidebar:
    st.header("Semi-Insight")
    st.divider()
    selected_category = st.radio("ì¹´í…Œê³ ë¦¬", CATEGORIES, index=0, label_visibility="collapsed")
    st.divider()
    
    with st.expander("ğŸ” API Key"):
        user_key = st.text_input("Key", type="password")
        if user_key: api_key = user_key
        elif "GEMINI_API_KEY" in st.secrets: api_key = st.secrets["GEMINI_API_KEY"]
        else: api_key = FALLBACK_API_KEY
    
    st.markdown("---")
    with st.expander("ğŸ“‰ Global Stock", expanded=True):
        stock_data = get_stock_prices_grouped()
        if stock_data:
            for cat, items in STOCK_CATEGORIES.items():
                st.markdown(f"<div class='stock-header'>{cat}</div>", unsafe_allow_html=True)
                for name, symbol in items.items():
                    info = stock_data.get(symbol)
                    if info:
                        c1, c2 = st.columns([1, 1.3])
                        c1.caption(f"**{name}**")
                        c2.metric("", info['Price'], info['Delta'], label_visibility="collapsed")
                        st.markdown("<hr style='margin: 2px 0; border-top: 1px dashed #f1f5f9;'>", unsafe_allow_html=True)

c_head, c_info = st.columns([3, 1])
with c_head: st.title(selected_category)

if selected_category == "Daily Report":
    st.info("â„¹ï¸ ë§¤ì¼ ì˜¤ì „ 6ì‹œ ê¸°ì¤€ ë°˜ë„ì²´ ì†Œì¬ê´€ë ¨ ì •ë³´ Report ì…ë‹ˆë‹¤.")

    now_kst = datetime.utcnow() + timedelta(hours=9)
    if now_kst.hour < 6:
        target_date = (now_kst - timedelta(days=1)).date()
    else:
        target_date = now_kst.date()
    target_date_str = target_date.strftime('%Y-%m-%d')
    
    with c_info:
        st.markdown(f"<div style='text-align:right; color:#888;'>Report Date<br><b>{target_date}</b></div>", unsafe_allow_html=True)

    with st.container(border=True):
        c1, c2 = st.columns([3, 1])
        new_kw = c1.text_input("ìˆ˜ì§‘ í‚¤ì›Œë“œ ì¶”ê°€", placeholder="ì˜ˆ: HBM, íŒ¨í‚¤ì§•", label_visibility="collapsed")
        if c2.button("ì¶”ê°€", use_container_width=True):
            if new_kw and new_kw not in st.session_state.keywords["Daily Report"]:
                st.session_state.keywords["Daily Report"].append(new_kw)
                save_keywords(st.session_state.keywords)
                st.rerun()
        
        daily_kws = st.session_state.keywords["Daily Report"]
        if daily_kws:
            st.write("")
            cols = st.columns(len(daily_kws) if len(daily_kws) < 8 else 8)
            for i, kw in enumerate(daily_kws):
                if cols[i % 8].button(f"{kw} Ã—", key=f"del_{kw}"):
                    st.session_state.keywords["Daily Report"].remove(kw)
                    save_keywords(st.session_state.keywords)
                    st.rerun()
        st.caption("âš ï¸ ê´€ì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ë©´ í•´ë‹¹ ì£¼ì œë¡œ ë³´ê³ ì„œì— ë°˜ì˜ë©ë‹ˆë‹¤. ë‹¨ í‚¤ì›Œë“œê°€ ëŠ˜ì–´ë‚˜ë©´ ì‹œìŠ¤í…œ ì˜¤ë¥˜ë°œìƒ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì™¼ìª½ ê° sector ë³„ Keyword ê²€ìƒ‰ì„ í™œìš©í•´ì£¼ì„¸ìš”")
    
    history = load_daily_history()
    today_report = next((h for h in history if h['date'] == target_date_str), None)
    
    if not today_report:
        st.info(f"ğŸ“¢ {target_date} ë¦¬í¬íŠ¸ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if st.button("ğŸš€ ê¸ˆì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘", type="primary"):
            status_box = st.status("ğŸš€ ë¦¬í¬íŠ¸ ìƒì„± í”„ë¡œì„¸ìŠ¤...", expanded=True)
            
            start_str = (datetime.combine(target_date, datetime.min.time()) - timedelta(hours=18)).strftime('%m/%d 12:00')
            end_str = (datetime.combine(target_date, datetime.min.time()) + timedelta(hours=6)).strftime('%m/%d 06:00')
            
            status_box.write(f"ğŸ“¡ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ({start_str} ~ {end_str})...")
            
            news_items = fetch_news_strict_window(daily_kws, target_date)
            
            if not news_items:
                status_box.update(label="âŒ ì§€ì •ëœ ì‹œê°„ ë²”ìœ„(ì „ì¼ 12ì‹œ~ë‹¹ì¼ 06ì‹œ) ë‚´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.", state="error")
            else:
                status_box.write(f"ğŸ§  AI ì‹¬ì¸µ ë¶„ì„ ì¤‘... (ê¸°ì‚¬ {len(news_items)}ê±´)")
                success, result = generate_report(api_key, news_items)
                
                if success:
                    save_data = {'date': target_date_str, 'report': result, 'articles': news_items}
                    save_daily_history(save_data)
                    status_box.update(label="ğŸ‰ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!", state="complete")
                    st.rerun()
                else:
                    status_box.update(label="âš ï¸ AI ë¶„ì„ ì‹¤íŒ¨", state="error")
                    st.error(result)
    else:
        st.success(f"âœ… {target_date} ë¦¬í¬íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        if st.button("ğŸ”„ ë¦¬í¬íŠ¸ ë‹¤ì‹œ ë§Œë“¤ê¸° (ë®ì–´ì“°ê¸°)"):
            status_box = st.status("ğŸš€ ë¦¬í¬íŠ¸ ì¬ìƒì„± ì¤‘...", expanded=True)
            news_items = fetch_news_strict_window(daily_kws, target_date)
            
            if news_items:
                success, result = generate_report(api_key, news_items)
                if success:
                    save_data = {'date': target_date_str, 'report': result, 'articles': news_items}
                    save_daily_history(save_data)
                    status_box.update(label="ğŸ‰ ì¬ìƒì„± ì™„ë£Œ!", state="complete")
                    st.rerun()
            else:
                status_box.error("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    if history:
        for entry in history:
            st.divider()
            st.markdown(f"<div class='history-header'>ğŸ“… {entry['date']} Daily Report</div>", unsafe_allow_html=True)
            st.markdown(f"<div class='report-box'>{entry['report']}</div>", unsafe_allow_html=True)
            
            with st.expander(f"ğŸ“š References (ê¸°ì‚¬ ì›ë¬¸) - {len(entry.get('articles', []))}ê±´"):
                st.markdown("#### ê¸°ì‚¬ ì›ë¬¸ ë§í¬")
                ref_cols = st.columns(2)
                for i, item in enumerate(entry.get('articles', [])):
                    col = ref_cols[i % 2]
                    with col:
                        st.markdown(f"""
                        <a href="{item['Link']}" target="_blank" class="ref-link">
                            <span class="ref-number">[{i+1}]</span> {item['Title']}
                        </a>
                        """, unsafe_allow_html=True)

else:
    with st.container(border=True):
        c1, c2, c3 = st.columns([2, 1, 1])
        new_kw = c1.text_input("í‚¤ì›Œë“œ", label_visibility="collapsed")
        if c2
