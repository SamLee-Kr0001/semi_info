import streamlit as st
import pandas as pd
import requests
import urllib3
from urllib.parse import quote
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import json
import os
import re
import time
import yfinance as yf

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==========================================
# 0. í˜ì´ì§€ ì„¤ì • ë° ì´ˆê¸°í™”
# ==========================================
st.set_page_config(layout="wide", page_title="Semi-Insight Hub", page_icon="ğŸ’ ")

CATEGORIES = ["Daily Report", "ê¸°ì—…ì •ë³´", "ë°˜ë„ì²´ ì •ë³´", "Photoresist", "Wet chemical", "CMP Slurry", "Process Gas", "Wafer", "Package"]

if 'news_data' not in st.session_state:
    st.session_state.news_data = {cat: [] for cat in CATEGORIES}

if 'keywords' not in st.session_state:
    st.session_state.keywords = {cat: [] for cat in CATEGORIES}

if 'daily_history' not in st.session_state:
    st.session_state.daily_history = []

st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@300;400;500;600;700&display=swap');
        html, body, .stApp { font-family: 'Pretendard', sans-serif; background-color: #F8FAFC; color: #1E293B; }
        
        .report-box { background-color: #FFFFFF; padding: 50px; border-radius: 12px; border: 1px solid #E2E8F0; box-shadow: 0 4px 20px rgba(0,0,0,0.05); margin-bottom: 30px; line-height: 1.8; color: #334155; font-size: 16px; }
        .report-box h2 { color: #1E3A8A; border-bottom: 2px solid #3B82F6; padding-bottom: 10px; margin-top: 30px; margin-bottom: 20px; font-size: 24px; font-weight: 700; }
        
        .news-card { background: white; padding: 15px; border-radius: 10px; border: 1px solid #E2E8F0; margin-bottom: 10px; }
        .news-title { font-size: 16px !important; font-weight: 700 !important; color: #111827 !important; text-decoration: none; display: block; margin-bottom: 6px; }
        .news-title:hover { color: #2563EB !important; text-decoration: underline; }
        .news-meta { font-size: 12px !important; color: #94A3B8 !important; }

        /* [ìˆ˜ì •] ì£¼ê°€ ì •ë³´ ìŠ¤íƒ€ì¼ (ê°€ë…ì„± í–¥ìƒ) */
        .stock-row { 
            display: flex; 
            justify-content: space-between; 
            align-items: center; 
            font-size: 14px; 
            padding: 5px 0; 
            border-bottom: 1px dashed #e2e8f0; 
        }
        .stock-name { font-weight: 600; color: #334155; }
        .stock-price { font-family: 'Consolas', monospace; font-weight: 600; font-size: 14px; }
        .up-color { color: #DC2626; } /* ë¹¨ê°• */
        .down-color { color: #2563EB; } /* íŒŒë‘ */
        .flat-color { color: #64748B; } /* íšŒìƒ‰ */
        .stock-header { font-size: 13px; font-weight: 700; color: #475569; margin-top: 15px; margin-bottom: 5px; border-bottom: 1px solid #E2E8F0; padding-bottom: 4px; }
        
        .ref-link { font-size: 0.9em; color: #555; text-decoration: none; display: block; margin-bottom: 6px; padding: 5px; border-radius: 4px; transition: background 0.2s; }
        .ref-link:hover { background-color: #F1F5F9; color: #2563EB; }
        .ref-number { font-weight: bold; color: #3B82F6; margin-right: 8px; background: #DBEAFE; padding: 2px 6px; border-radius: 4px; font-size: 0.8em; }
    </style>
""", unsafe_allow_html=True)

# [ìˆ˜ì •] ì£¼ì‹ ì¢…ëª© ì •ì˜ (ë°ì´í„° ì •í™•ë„ ìœ„í•´ í‹°ì»¤ ì ê²€)
STOCK_CATEGORIES = {
    "ğŸ­ Chipmakers": {
        "Samsung": "005930.KS", "SK Hynix": "000660.KS", "Micron": "MU",
        "TSMC": "TSM", "Intel": "INTC", "SMIC": "0981.HK"
    },
    "ğŸ§  Fabless": {
        "Nvidia": "NVDA", "Broadcom": "AVGO"
    },
    "âš™ï¸ Equipment": {
        "ASML": "ASML", "AMAT": "AMAT", "Lam Res": "LRCX", 
        "TEL": "8035.T", "KLA": "KLAC", "Hanmi": "042700.KS", "Jusung": "036930.KS"
    },
    "ğŸ§ª Materials": {
        "Shin-Etsu": "4063.T", "Sumitomo": "4005.T", "TOK": "4186.T", 
        "Nissan Chem": "4021.T", "Merck": "MRK.DE", "Air Liquide": "AI.PA", "Qnity (Q)": "Q",  
        "Linde": "LIN", "Soulbrain": "357780.KS", "Dongjin": "005290.KS", 
        "ENF": "102710.KS", "Ycchem": "232140.KS", "Samsung SDI": "006400.KS"
    }
}

# ==========================================
# 1. ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜
# ==========================================
KEYWORD_FILE = 'keywords.json'
HISTORY_FILE = 'daily_history.json'

# [í•µì‹¬ ìˆ˜ì •] ì£¼ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ë¡œì§ ì „ë©´ ê°œí¸ (ì •í™•ë„ ìµœìš°ì„ )
@st.cache_data(ttl=300) # 5ë¶„ ìºì‹œ
def get_stock_prices_grouped():
    result_map = {}
    
    # 1. ëª¨ë“  ì¢…ëª©ì„ ìˆœíšŒí•˜ë©° ê°œë³„ ì²˜ë¦¬ (Batch ì²˜ë¦¬ ì‹œ ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥ì„± ì°¨ë‹¨)
    for cat, items in STOCK_CATEGORIES.items():
        for name, symbol in items.items():
            try:
                ticker = yf.Ticker(symbol)
                
                # [ì „ëµ 1] Fast Info (ì‹¤ì‹œê°„ ë°ì´í„° ìµœìš°ì„ )
                try:
                    # yfinance ìµœì‹  ë²„ì „ì˜ fast_info ì‚¬ìš©
                    current = ticker.fast_info['last_price']
                    prev = ticker.fast_info['previous_close']
                except:
                    # [ì „ëµ 2] ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 1ë¶„ë´‰ ë°ì´í„° í™•ì¸ (ì¥ì¤‘)
                    try:
                        hist = ticker.history(period="1d", interval="1m")
                        if not hist.empty:
                            current = hist['Close'].iloc[-1]
                            prev = ticker.info.get('previousClose', current) # infoì—ì„œ ì „ì¼ì¢…ê°€ ì‹œë„
                        else:
                            raise ValueError("No data")
                    except:
                        # [ì „ëµ 3] ìµœí›„ì˜ ìˆ˜ë‹¨: 5ì¼ì¹˜ ë°ì´í„°
                        hist = ticker.history(period="5d")
                        current = hist['Close'].iloc[-1]
                        prev = hist['Close'].iloc[-2]

                # ë“±ë½ë¥  ê³„ì‚°
                change = current - prev
                pct = (change / prev) * 100
                
                # í†µí™” ê¸°í˜¸
                if ".KS" in symbol: cur_sym = "â‚©"
                elif ".T" in symbol: cur_sym = "Â¥"
                elif ".HK" in symbol: cur_sym = "HK$"
                elif ".DE" in symbol or ".PA" in symbol: cur_sym = "â‚¬"
                else: cur_sym = "$"
                
                # ê°€ê²© í¬ë§·íŒ… (ì†Œìˆ˜ì  ì²˜ë¦¬)
                if cur_sym in ["â‚©", "Â¥"]:
                    fmt_price = f"{cur_sym}{current:,.0f}"
                else:
                    fmt_price = f"{cur_sym}{current:,.2f}"
                
                # ìƒ‰ìƒ ë° í™”ì‚´í‘œ (í•œêµ­ì‹: ìƒìŠ¹=ë¹¨ê°•)
                if change > 0:
                    color_class = "up-color"
                    arrow = "â–²"
                    sign = "+"
                elif change < 0:
                    color_class = "down-color"
                    arrow = "â–¼"
                    sign = ""
                else:
                    color_class = "flat-color"
                    arrow = "-"
                    sign = ""
                
                # HTML ìƒì„±
                html_str = f"""
                <div class="stock-row">
                    <span class="stock-name">{name}</span>
                    <span class="stock-price {color_class}">
                        {fmt_price} <span style="font-size:0.9em; margin-left:3px;">{arrow} {sign}{pct:.2f}%</span>
                    </span>
                </div>
                """
                result_map[name] = html_str # ì´ë¦„(Key)ì— ë§¤í•‘
                
            except Exception:
                # ì—ëŸ¬ë‚˜ë©´ ë¹ˆì¹¸ í˜¹ì€ ì´ì „ ë°ì´í„° ìœ ì§€
                pass
                
    return result_map

def load_keywords():
    data = {cat: [] for cat in CATEGORIES}
    if os.path.exists(KEYWORD_FILE):
        try:
            with open(KEYWORD_FILE, 'r', encoding='utf-8') as f:
                loaded = json.load(f)
            for k, v in loaded.items():
                if k in data: data[k] = v
        except: pass
    if not data.get("Daily Report"): 
        data["Daily Report"] = ["ë°˜ë„ì²´", "ë°˜ë„ì²´ ì†Œì¬", "ë°˜ë„ì²´ ê³µê¸‰ë§", "í¬í† ë¥˜ ê·œì œ", "ì¤‘êµ­ ë°˜ë„ì²´", "ë¯¸êµ­ ë°˜ë„ì²´", "ì¼ë³¸ ë°˜ë„ì²´"] 
    return data

def save_keywords(data):
    try:
        with open(KEYWORD_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except: pass

def load_daily_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: return []
    return []

def save_daily_history(new_report_data):
    history = load_daily_history()
    history = [h for h in history if h['date'] != new_report_data['date']]
    history.insert(0, new_report_data)
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=4)
    except: pass

# ==========================================
# 2. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
# ==========================================
def fetch_news(keywords, days=1, limit=20, strict_time=False):
    all_items = []
    now_kst = datetime.utcnow() + timedelta(hours=9)
    end_target = datetime(now_kst.year, now_kst.month, now_kst.day, 6, 0, 0)
    if now_kst.hour < 6:
        end_target -= timedelta(days=1)
    start_target = end_target - timedelta(hours=18)
    
    for kw in keywords:
        url = f"https://news.google.com/rss/search?q={quote(kw)}+when:{days}d&hl=ko&gl=KR&ceid=KR:ko"
        try:
            res = requests.get(url, timeout=5, verify=False)
            soup = BeautifulSoup(res.content, 'xml')
            items = soup.find_all('item')
            for item in items:
                is_valid = True
                if strict_time:
                    try:
                        pub_date_str = item.pubDate.text
                        pub_date = datetime.strptime(pub_date_str, "%a, %d %b %Y %H:%M:%S %Z")
                        pub_date_kst = pub_date + timedelta(hours=9)
                        if not (start_target <= pub_date_kst <= end_target):
                            is_valid = False
                    except: is_valid = True
                
                if is_valid:
                    all_items.append({
                        'Title': item.title.text,
                        'Link': item.link.text,
                        'Date': item.pubDate.text,
                        'Source': item.source.text if item.source else "Google News"
                    })
        except: pass
        time.sleep(0.1)
        
    df = pd.DataFrame(all_items)
    if not df.empty:
        df = df.drop_duplicates(subset=['Title'])
        return df.head(limit).to_dict('records')
    return []

# ==========================================
# 3. AI ë¦¬í¬íŠ¸ ìƒì„±
# ==========================================
def get_available_models(api_key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    try:
        res = requests.get(url, timeout=10)
        if res.status_code == 200:
            data = res.json()
            return [m['name'].replace("models/", "") for m in data.get('models', []) if 'generateContent' in m.get('supportedGenerationMethods', [])]
    except: pass
    return []

def inject_links_to_report(report_text, news_data):
    def replace_match(match):
        try:
            idx_str = match.group(1)
            idx = int(idx_str) - 1
            if 0 <= idx < len(news_data):
                link = news_data[idx]['Link']
                return f"[[{idx_str}]]({link})"
        except: pass
        return match.group(0)
    return re.sub(r'\[(\d+)\]', replace_match, report_text)

def generate_report_with_citations(api_key, news_data):
    models = get_available_models(api_key)
    if not models:
        models = ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"]
    
    news_context = ""
    for i, item in enumerate(news_data):
        news_context += f"[{i+1}] {item['Title']} (Source: {item['Source']})\n"

    prompt = f"""
    ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ë°˜ë„ì²´ íˆ¬ì ë° ì „ëµ ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. 
    ì œê³µëœ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ **[ì¼ì¼ ë°˜ë„ì²´ ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ]**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

    **[ì‘ì„± ì›ì¹™ - ë§¤ìš° ì¤‘ìš”]**
    1. **ë‹¨ìˆœ ìš”ì•½ ê¸ˆì§€**: ë‰´ìŠ¤ ì œëª©ì„ ë‹¨ìˆœíˆ ë‚˜ì—´í•˜ê±°ë‚˜ ë²ˆì—­í•˜ì§€ ë§ˆì„¸ìš”.
    2. **ì„œìˆ í˜• ì‘ì„±**: ì´ìŠˆë³„ë¡œ í˜„ìƒ/ì›ì¸/ì „ë§ì„ ê°œì¡°ì‹(Bullet points)ìœ¼ë¡œ ë‚˜ëˆ„ì§€ ë§ê³ , **í•˜ë‚˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë…¼ë¦¬ì  íë¦„ì„ ê°€ì§„ ì¤„ê¸€(Narrative Paragraph)**ë¡œ ì„œìˆ í•˜ì„¸ìš”. ì „ë¬¸ì ì¸ ë¬¸ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    3. **ê·¼ê±° ëª…ì‹œ**: ëª¨ë“  ì£¼ì¥ì´ë‚˜ ì‚¬ì‹¤ ì–¸ê¸‰ ì‹œ ë°˜ë“œì‹œ ì œê³µëœ ë‰´ìŠ¤ ë²ˆí˜¸ **[1], [2]**ë¥¼ ë¬¸ì¥ ëì— ì¸ìš©í•˜ì„¸ìš”.

    [ë‰´ìŠ¤ ë°ì´í„°]
    {news_context}
    
    [ë³´ê³ ì„œ êµ¬ì¡° (Markdown)]
    ## ğŸ“Š Executive Summary (ì‹œì¥ ì´í‰)
    - ì˜¤ëŠ˜ ë°˜ë„ì²´ ì‹œì¥ì˜ í•µì‹¬ ë¶„ìœ„ê¸°ì™€ ê°€ì¥ ì¤‘ìš”í•œ ë³€í™”ë¥¼ 3~4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½.

    ## ğŸš¨ Key Issues & Deep Dive (í•µì‹¬ ì´ìŠˆ ì‹¬ì¸µ ë¶„ì„)
    - ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ 2~3ê°€ì§€ë¥¼ ì„ ì •í•˜ì—¬ ì†Œì œëª©ì„ ë‹¬ê³  ë¶„ì„í•˜ì„¸ìš”.
    - **ì¤‘ìš”**: í˜„ìƒ, ì›ì¸, ì „ë§ì„ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•˜ì§€ ë§ê³ , **ê¹Šì´ ìˆëŠ” ì„œìˆ í˜• ë¬¸ë‹¨**ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì‚¬ê±´ì˜ ë°°ê²½ë¶€í„° íŒŒê¸‰ íš¨ê³¼ê¹Œì§€ ë§¤ë„ëŸ½ê²Œ ì—°ê²°ë˜ë„ë¡ í•˜ì„¸ìš”.
    - ë°˜ë“œì‹œ ì¸ìš© ë²ˆí˜¸[n]ë¥¼ í¬í•¨í•  ê²ƒ.

    ## ğŸ•¸ï¸ Supply Chain & Tech Trends (ê³µê¸‰ë§ ë° ê¸°ìˆ  ë™í–¥)
    - ì†Œë¶€ì¥, íŒŒìš´ë“œë¦¬, ë©”ëª¨ë¦¬ ë“± ì„¹í„°ë³„ ì£¼ìš” ë‹¨ì‹ ì„ ì¢…í•©í•˜ì—¬ ì„œìˆ .

    ## ğŸ’¡ Analyst's View (íˆ¬ì ì•„ì´ë””ì–´)
    - ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ê°€ ì£¼ëŠ” ì‹œì‚¬ì ê³¼ í–¥í›„ ê´€ì „ í¬ì¸íŠ¸ í•œ ì¤„ ì •ë¦¬.
    """
    
    headers = {'Content-Type': 'application/json'}
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [{"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"}]
    }

    for model in models:
        if "vision" in model: continue
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
        try:
            response = requests.post(url, headers=headers, json=data, timeout=60)
            if response.status_code == 200:
                res_json = response.json()
                if 'candidates' in res_json and res_json['candidates']:
                    raw_text = res_json['candidates'][0]['content']['parts'][0]['text']
                    return True, inject_links_to_report(raw_text, news_data)
            elif response.status_code == 429:
                time.sleep(1) 
                continue
        except: continue
            
    return False, "AI ë¶„ì„ ì‹¤íŒ¨ (ëª¨ë“  ëª¨ë¸ ì‘ë‹µ ì—†ìŒ)"

# ==========================================
# 4. ë©”ì¸ ì•± UI
# ==========================================
if 'keywords' not in st.session_state: st.session_state.keywords = load_keywords()

with st.sidebar:
    st.header("Semi-Insight")
    st.divider()
    selected_category = st.radio("ì¹´í…Œê³ ë¦¬", CATEGORIES, index=0, label_visibility="collapsed")
    st.divider()
    
    # API Key
    with st.expander("ğŸ” API Key"):
        user_key = st.text_input("Key", type="password")
        if user_key: api_key = user_key
        elif "GEMINI_API_KEY" in st.secrets: api_key = st.secrets["GEMINI_API_KEY"]
        else: api_key = ""
    
    st.markdown("---")
    
    # [í•µì‹¬ ìˆ˜ì •] ì£¼ê°€ ì„¹ì…˜ (ì—…ë°ì´íŠ¸ ë²„íŠ¼ + HTML ë Œë”ë§)
    with st.expander("ğŸ“‰ Global Stock", expanded=True):
        if st.button("ğŸ”„ ì‹œì„¸ ì—…ë°ì´íŠ¸", use_container_width=True):
            get_stock_prices_grouped.clear() # ìºì‹œ ê°•ì œ ì‚­ì œ
            st.rerun()
            
        stock_data = get_stock_prices_grouped()
        if stock_data:
            for cat, items in STOCK_CATEGORIES.items():
                st.markdown(f"<div class='stock-header'>{cat}</div>", unsafe_allow_html=True)
                for name, symbol in items.items():
                    # ì´ë¦„ìœ¼ë¡œ ë§¤í•‘ëœ HTML ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    html_info = stock_data.get(name)
                    if html_info:
                        st.markdown(html_info, unsafe_allow_html=True)
    
    st.caption("â„¹ï¸ 'ì‹œì„¸ ì—…ë°ì´íŠ¸' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ìµœì‹ ê°€ë¡œ ê°±ì‹ ë©ë‹ˆë‹¤.")

c_head, c_info = st.columns([3, 1])
with c_head: st.title(selected_category)

# ----------------------------------
# [Mode 1] Daily Report
# ----------------------------------
if selected_category == "Daily Report":
    st.info("â„¹ï¸ ë§¤ì¼ ì˜¤ì „ 6ì‹œ ê¸°ì¤€ ë°˜ë„ì²´ ì†Œì¬ê´€ë ¨ ì •ë³´ Report ì…ë‹ˆë‹¤.")
    now_kst = datetime.utcnow() + timedelta(hours=9)
    if now_kst.hour < 6:
        target_date = (now_kst - timedelta(days=1)).date()
    else:
        target_date = now_kst.date()
    target_date_str = target_date.strftime('%Y-%m-%d')
    
    with c_info:
        st.markdown(f"<div style='text-align:right; color:#888;'>Report Date<br><b>{target_date}</b></div>", unsafe_allow_html=True)

    with st.container(border=True):
        c1, c2 = st.columns([3, 1])
        new_kw = c1.text_input("ìˆ˜ì§‘ í‚¤ì›Œë“œ ì¶”ê°€", placeholder="ì˜ˆ: HBM, íŒ¨í‚¤ì§•", label_visibility="collapsed")
        if c2.button("ì¶”ê°€", use_container_width=True):
            if new_kw and new_kw not in st.session_state.keywords["Daily Report"]:
                st.session_state.keywords["Daily Report"].append(new_kw)
                save_keywords(st.session_state.keywords)
                st.rerun()
        
        daily_kws = st.session_state.keywords["Daily Report"]
        if daily_kws:
            st.write("")
            cols = st.columns(len(daily_kws) if len(daily_kws) < 8 else 8)
            for i, kw in enumerate(daily_kws):
                if cols[i % 8].button(f"{kw} Ã—", key=f"del_{kw}"):
                    st.session_state.keywords["Daily Report"].remove(kw)
                    save_keywords(st.session_state.keywords)
                    st.rerun()
        
        st.caption("âš ï¸ ê´€ì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ë©´ í•´ë‹¹ ì£¼ì œë¡œ ë³´ê³ ì„œì— ë°˜ì˜ë©ë‹ˆë‹¤. ë‹¨ í‚¤ì›Œë“œê°€ ëŠ˜ì–´ë‚˜ë©´ ì‹œìŠ¤í…œ ì˜¤ë¥˜ë°œìƒ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì™¼ìª½ ê° sector ë³„ Keyword ê²€ìƒ‰ì„ í™œìš©í•´ì£¼ì„¸ìš”")
    
    history = load_daily_history()
    today_report = next((h for h in history if h['date'] == target_date_str), None)
    
    if not today_report:
        st.info(f"ğŸ“¢ {target_date} ë¦¬í¬íŠ¸ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if st.button("ğŸš€ ê¸ˆì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘", type="primary"):
            status_box = st.status("ğŸš€ ë¦¬í¬íŠ¸ ìƒì„± í”„ë¡œì„¸ìŠ¤...", expanded=True)
            status_box.write(f"ğŸ“¡ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ (ì „ì¼ 12:00 ~ ê¸ˆì¼ 06:00)...")
            news_items = fetch_news(daily_kws, days=2, strict_time=True)
            
            if not news_items:
                status_box.update(label="âš ï¸ ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ê°€ ì—†ì–´ ë²”ìœ„ë¥¼ í™•ì¥í•©ë‹ˆë‹¤ (ìµœê·¼ 24ì‹œê°„).", state="running")
                time.sleep(1)
                news_items = fetch_news(daily_kws, days=1, strict_time=False)
            
            if not news_items:
                status_box.update(label="âŒ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.", state="error")
            else:
                status_box.write(f"ğŸ§  AI ì‹¬ì¸µ ë¶„ì„ ì¤‘... (ê¸°ì‚¬ {len(news_items)}ê±´)")
                success, result = generate_report_with_citations(api_key, news_items)
                if success:
                    save_data = {'date': target_date_str, 'report': result, 'articles': news_items}
                    save_daily_history(save_data)
                    status_box.update(label="ğŸ‰ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!", state="complete")
                    st.rerun()
                else:
                    status_box.update(label="âš ï¸ AI ë¶„ì„ ì‹¤íŒ¨", state="error")
                    st.error(result)
    else:
        st.success(f"âœ… {target_date} ë¦¬í¬íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        if st.button("ğŸ”„ ë¦¬í¬íŠ¸ ë‹¤ì‹œ ë§Œë“¤ê¸° (ë®ì–´ì“°ê¸°)"):
            status_box = st.status("ğŸš€ ë¦¬í¬íŠ¸ ì¬ìƒì„± ì¤‘...", expanded=True)
            news_items = fetch_news(daily_kws, days=1, strict_time=False)
            if news_items:
                success, result = generate_report_with_citations(api_key, news_items)
                if success:
                    save_data = {'date': target_date_str, 'report': result, 'articles': news_items}
                    save_daily_history(save_data)
                    status_box.update(label="ğŸ‰ ì¬ìƒì„± ì™„ë£Œ!", state="complete")
                    st.rerun()

    if history:
        for entry in history:
            st.divider()
            st.markdown(f"<div class='history-header'>ğŸ“… {entry['date']} Daily Report</div>", unsafe_allow_html=True)
            st.markdown(f"<div class='report-box'>{entry['report']}</div>", unsafe_allow_html=True)
            with st.expander(f"ğŸ“š References (ê¸°ì‚¬ ì›ë¬¸) - {len(entry.get('articles', []))}ê±´"):
                st.markdown("#### ê¸°ì‚¬ ì›ë¬¸ ë§í¬")
                ref_cols = st.columns(2)
                for i, item in enumerate(entry.get('articles', [])):
                    col = ref_cols[i % 2]
                    with col:
                        st.markdown(f"""
                        <a href="{item['Link']}" target="_blank" class="ref-link">
                            <span class="ref-number">[{i+1}]</span> {item['Title']}
                        </a>
                        """, unsafe_allow_html=True)

# ----------------------------------
# [Mode 2] General Category
# ----------------------------------
else:
    with st.container(border=True):
        c1, c2, c3 = st.columns([2, 1, 1])
        new_kw = c1.text_input("í‚¤ì›Œë“œ", label_visibility="collapsed")
        if c2.button("ì¶”ê°€", use_container_width=True):
            if new_kw:
                st.session_state.keywords[selected_category].append(new_kw)
                save_keywords(st.session_state.keywords)
                st.rerun()
        if c3.button("ì‹¤í–‰", type="primary", use_container_width=True):
            kws = st.session_state.keywords[selected_category]
            if kws:
                news = fetch_news(kws, limit=20)
                st.session_state.news_data[selected_category] = news
                st.rerun()
        curr_kws = st.session_state.keywords[selected_category]
        if curr_kws:
            st.write("")
            cols = st.columns(8)
            for i, kw in enumerate(curr_kws):
                if cols[i%8].button(f"{kw} Ã—", key=f"gdel_{kw}"):
                    st.session_state.keywords[selected_category].remove(kw)
                    save_keywords(st.session_state.keywords)
                    st.rerun()

    data = st.session_state.news_data.get(selected_category, [])
    if data:
        st.write(f"ì´ {len(data)}ê±´ ìˆ˜ì§‘ë¨")
        for item in data:
            st.markdown(f"""
            <div class="news-card">
                <div class="news-meta">{item['Source']} | {item['Date']}</div>
                <a href="{item['Link']}" target="_blank" class="news-title">{item['Title']}</a>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("ìƒë‹¨ì˜ 'ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")
