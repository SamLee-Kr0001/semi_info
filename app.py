import streamlit as st
import pandas as pd
import requests
import urllib3
from urllib.parse import quote
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import json
import os
import re
import html  # HTML íŠ¹ìˆ˜ë¬¸ì ê¹¨ì§ ë°©ì§€ìš©

# Google Gemini
import google.generativeai as genai

# ==========================================
# 0. í˜ì´ì§€ ì„¤ì • ë° CSS (ë””ìì¸ í•µì‹¬)
# ==========================================
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

st.set_page_config(layout="wide", page_title="Semi-Insight Hub", page_icon="ğŸ’ ")

# CSS ì£¼ì…
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@300;400;500;600;700&display=swap');
        
        html, body, [class*="css"] {
            font-family: 'Pretendard', sans-serif;
        }
        
        /* 1. ì‚¬ì´ë“œë°” ë¼ë””ì˜¤ ë²„íŠ¼ -> "ë©”ë‰´ ë²„íŠ¼" ìŠ¤íƒ€ì¼ë¡œ ë³€ì‹  */
        [data-testid="stSidebar"] {
            background-color: #F8FAFC;
            border-right: 1px solid #E2E8F0;
        }
        /* ë¼ë””ì˜¤ ë²„íŠ¼ì˜ ë™ê·¸ë¼ë¯¸ ìˆ¨ê¸°ê¸° */
        div.row-widget.stRadio > div[role="radiogroup"] > label > div:first-child {
            display: none;
        }
        /* ë²„íŠ¼ ëª¨ì–‘ ë§Œë“¤ê¸° */
        div.row-widget.stRadio > div[role="radiogroup"] > label {
            background-color: transparent;
            padding: 12px 16px;
            border-radius: 8px;
            margin-bottom: 4px;
            border: 1px solid transparent;
            transition: all 0.2s ease;
            cursor: pointer;
            width: 100%;
            display: flex; /* í…ìŠ¤íŠ¸ ì •ë ¬ */
            align-items: center;
        }
        /* ë§ˆìš°ìŠ¤ ì˜¬ë ¸ì„ ë•Œ */
        div.row-widget.stRadio > div[role="radiogroup"] > label:hover {
            background-color: #FFFFFF;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
            color: #2563EB;
        }
        /* ì„ íƒë˜ì—ˆì„ ë•Œ (Active) */
        div.row-widget.stRadio > div[role="radiogroup"] > label[data-baseweb="radio"] {
            background-color: #EFF6FF; /* ì—°í•œ íŒŒë€ìƒ‰ */
            border: 1px solid #BFDBFE;
            color: #1D4ED8; /* ì§„í•œ íŒŒë€ìƒ‰ í…ìŠ¤íŠ¸ */
            font-weight: 700;
        }
        
        /* 2. ë‰´ìŠ¤ ì¹´ë“œ ìŠ¤íƒ€ì¼ (HTML ì˜¤ë¥˜ ë°©ì§€ êµ¬ì¡°) */
        .news-card-container {
            background-color: #FFFFFF !important; /* ë‹¤í¬ëª¨ë“œ ë¬´ì‹œí•˜ê³  í° ë°°ê²½ */
            border: 1px solid #E2E8F0;
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 0px; /* Grid ê°„ê²© ì¡°ì ˆ */
            height: 100%;
            min-height: 220px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.03);
            transition: transform 0.2s, box-shadow 0.2s;
            display: flex;
            flex-direction: column;
            justify-content: space-between;
        }
        .news-card-container:hover {
            transform: translateY(-4px);
            box-shadow: 0 10px 20px rgba(0,0,0,0.08);
            border-color: #6366F1;
        }
        
        /* í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ ê°•ì œ ì§€ì • (ë‹¤í¬ëª¨ë“œ í˜¸í™˜ì„±) */
        .card-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 12px;
        }
        .card-source {
            font-size: 0.75rem;
            font-weight: 600;
            color: #64748B !important;
            background-color: #F1F5F9;
            padding: 4px 8px;
            border-radius: 6px;
        }
        .card-title {
            font-size: 1.1rem;
            font-weight: 700;
            color: #1E293B !important;
            text-decoration: none;
            line-height: 1.4;
            margin-bottom: 8px;
            display: block;
        }
        .card-title:hover {
            color: #4F46E5 !important;
            text-decoration: underline;
        }
        .card-snippet {
            font-size: 0.9rem;
            color: #475569 !important;
            line-height: 1.5;
            margin-bottom: 16px;
            display: -webkit-box;
            -webkit-line-clamp: 3;
            -webkit-box-orient: vertical;
            overflow: hidden;
            flex-grow: 1;
        }
        .card-footer {
            border-top: 1px solid #F1F5F9;
            padding-top: 12px;
            font-size: 0.8rem;
            color: #94A3B8 !important;
            display: flex;
            justify-content: space-between;
        }

        /* 3. ì»¨íŠ¸ë¡¤ íŒ¨ë„ */
        .control-panel {
            background-color: white;
            padding: 15px 20px;
            border-radius: 12px;
            border: 1px solid #E2E8F0;
            box-shadow: 0 1px 2px rgba(0,0,0,0.05);
            margin-bottom: 25px;
        }
    </style>
""", unsafe_allow_html=True)

CATEGORIES = [
    "ê¸°ì—…ì •ë³´", "ë°˜ë„ì²´ ì •ë³´", "Photoresist", "Wet chemical", "CMP Slurry", 
    "Process Gas", "Precursor", "Metal target", "Wafer"
]

# ==========================================
# 1. ë°ì´í„° ê´€ë¦¬ ë° ìœ í‹¸ë¦¬í‹°
# ==========================================
KEYWORD_FILE = 'keywords.json'

def load_keywords():
    data = {cat: [] for cat in CATEGORIES}
    if os.path.exists(KEYWORD_FILE):
        try:
            with open(KEYWORD_FILE, 'r', encoding='utf-8') as f:
                loaded = json.load(f)
            for k, v in loaded.items():
                if k in data: data[k] = v
        except: pass
    return data

def save_keywords(data):
    try:
        with open(KEYWORD_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except: pass

if 'keywords' not in st.session_state: st.session_state.keywords = load_keywords()
if 'news_data' not in st.session_state: st.session_state.news_data = {cat: [] for cat in CATEGORIES}
if 'last_update' not in st.session_state: st.session_state.last_update = None

# ==========================================
# 2. ë¡œì§: í¬ë¡¤ë§ & AI (ì•ˆì •ì„± ê°•í™”)
# ==========================================
def make_smart_query(keyword, country_code):
    base_kw = keyword
    negatives = "-TikTok -í‹±í†¡ -douyin -dance -shorts -reels -viral -music -game -soccer"
    contexts = {
        'KR': "(ë°˜ë„ì²´ OR ì†Œì OR ê³µì • OR ì†Œì¬ OR íŒŒìš´ë“œë¦¬ OR íŒ¹ OR ì–‘ì‚°)",
        'CN': "(åŠå¯¼ä½“ OR èŠ¯ç‰‡ OR æ™¶åœ† OR å…‰åˆ»èƒ¶ OR èš€åˆ» OR å°è£…)",
        'HK': "(åŠå¯¼ä½“ OR èŠ¯ç‰‡ OR æ™¶åœ† OR å…‰åˆ»èƒ¶ OR èš€åˆ» OR å°è£…)",
        'TW': "(åŠå°é«” OR æ™¶ç‰‡ OR æ™¶åœ“ OR å…‰é˜» OR è•åˆ» OR å°è£)",
        'JP': "(åŠå°ä½“ OR ã‚·ãƒªã‚³ãƒ³ OR ã‚¦ã‚§ãƒ¼ãƒ OR ãƒ¬ã‚¸ã‚¹ãƒˆ)",
        'US': "(semiconductor OR chip OR fab OR foundry OR wafer OR lithography)"
    }
    context = contexts.get(country_code, contexts['US'])
    return f'{base_kw} AND {context} {negatives}'

def filter_with_gemini(articles, api_key):
    if not articles or not api_key: return articles
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        content_text = ""
        for i, item in enumerate(articles[:40]):
            # íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ì˜¤ë¥˜ ë°©ì§€
            safe_snip = re.sub(r'[^\w\s]', '', item.get('Snippet', ''))[:100]
            content_text += f"ID_{i+1} | Title: {item['Title']} | Snip: {safe_snip}\n"
            
        prompt = f"""
        Role: Semiconductor B2B Analyst.
        Task: Identify valid industry news.
        Rules: Keep Fab, Tech, Materials, Equipment. Reject Consumer gadgets/Games/Stocks.
        Data: {content_text}
        Output: Return ONLY the IDs (e.g., 1, 3, 5) of valid articles.
        """
        response = model.generate_content(prompt)
        nums = re.findall(r'\d+', response.text)
        valid_indices = [int(n)-1 for n in nums]
        
        filtered = []
        for idx in valid_indices:
            if 0 <= idx < len(articles):
                articles[idx]['AI_Verified'] = True
                filtered.append(articles[idx])
        return filtered if filtered else articles
    except: return articles

def crawl_google_rss(keyword, country_code, language):
    results = []
    smart_query = make_smart_query(keyword, country_code)
    url = f"https://news.google.com/rss/search?q={quote(smart_query)}&hl={language}&gl={country_code}&ceid={country_code}:{language}"
    
    try:
        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=5, verify=False)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'xml')
            for item in soup.find_all('item')[:5]:
                src = item.source.text if item.source else "Google"
                raw_d = item.description.text if item.description else ""
                snip = BeautifulSoup(raw_d, "html.parser").get_text(strip=True)[:200]
                
                pub_date = item.pubDate.text if item.pubDate else str(datetime.now())
                try: dt_obj = pd.to_datetime(pub_date).to_pydatetime()
                except: dt_obj = datetime.now()

                results.append({
                    'Title': item.title.text, 'Source': src, 'Date': dt_obj,
                    'Link': item.link.text, 'Keyword': keyword, 'Snippet': snip,
                    'AI_Verified': False
                })
    except: pass
    return results

def perform_crawling(category, start_date, end_date, api_key):
    kws = st.session_state.keywords.get(category, [])
    if not kws: return
    
    start_dt = datetime.combine(start_date, datetime.min.time())
    end_dt = datetime.combine(end_date, datetime.max.time())
    
    with st.spinner(f"ğŸŒ [{category}] ê¸€ë¡œë²Œ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° AI ë¶„ì„ ì¤‘..."):
        all_news = []
        for kw in kws:
            for cc, lang in [('KR','ko'), ('US','en'), ('TW','zh-TW')]:
                all_news.extend(crawl_google_rss(kw, cc, lang))
        
        df = pd.DataFrame(all_news)
        if not df.empty:
            df = df[(df['Date'] >= start_dt) & (df['Date'] <= end_dt)]
            df = df.drop_duplicates(subset=['Title']).sort_values('Date', ascending=False)
            final_list = df.head(60).to_dict('records')
            
            if api_key and final_list:
                final_list = filter_with_gemini(final_list, api_key)
            st.session_state.news_data[category] = final_list
        else:
             st.session_state.news_data[category] = []

# ==========================================
# 3. ì‚¬ì´ë“œë°” UI (ë©”ë‰´ ìŠ¤íƒ€ì¼ ë¼ë””ì˜¤ ë²„íŠ¼)
# ==========================================
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2331/2331966.png", width=40)
    st.markdown("<h3 style='margin-top:0'>Semi-Insight Hub</h3>", unsafe_allow_html=True)
    st.caption("Global Market Intelligence")
    st.markdown("---")
    
    st.markdown("#### ğŸ“‚ Target Domain")
    # ë¼ë””ì˜¤ ë²„íŠ¼ì´ì§€ë§Œ CSSë¡œ ë²„íŠ¼ ë©”ë‰´ì²˜ëŸ¼ ë³´ì´ê²Œ ì²˜ë¦¬ë¨
    selected_category = st.radio(
        "ì¹´í…Œê³ ë¦¬ ì„ íƒ", 
        CATEGORIES, 
        label_visibility="collapsed"
    )
    
    st.markdown("---")
    with st.expander("ğŸ” API Settings", expanded=False):
        api_key = st.text_input("Gemini API Key", type="password")
        if not api_key and "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            st.success("API Key Loaded")
    
    st.markdown("<div style='font-size:0.8em; color:#888; margin-top:20px'>Developed by LSH</div>", unsafe_allow_html=True)

# ==========================================
# 4. ë©”ì¸ UI (ì»¨íŠ¸ë¡¤ íŒ¨ë„ & ì¹´ë“œ ê·¸ë¦¬ë“œ)
# ==========================================

# ìƒë‹¨ í—¤ë”
c_h1, c_h2 = st.columns([3, 1])
with c_h1: st.title(selected_category)
with c_h2: 
    if st.session_state.last_update:
        st.caption(f"Last Update: {st.session_state.last_update}")

# ì»¨íŠ¸ë¡¤ íŒ¨ë„
st.markdown('<div class="control-panel">', unsafe_allow_html=True)
c1, c2, c3, c4 = st.columns([2, 3, 1, 1.5])

with c1:
    period = st.selectbox("ê¸°ê°„ ì„¤ì •", ["1 Month", "3 Months", "Custom"], label_visibility="collapsed")
    today = datetime.now().date()
    if period == "1 Month": s_date, e_date = today - timedelta(days=30), today
    elif period == "3 Months": s_date, e_date = today - timedelta(days=90), today
    else: s_date, e_date = today - timedelta(days=7), today

with c2:
    new_kw = st.text_input("í‚¤ì›Œë“œ", placeholder="Add keyword...", label_visibility="collapsed")
with c3:
    if st.button("ì¶”ê°€", use_container_width=True):
        if new_kw and new_kw not in st.session_state.keywords[selected_category]:
            st.session_state.keywords[selected_category].append(new_kw)
            save_keywords(st.session_state.keywords)
            st.rerun()
with c4:
    if st.button("ğŸš€ ì‹¤í–‰", type="primary", use_container_width=True):
        perform_crawling(selected_category, s_date, e_date, api_key)
        st.session_state.last_update = datetime.now().strftime("%Y-%m-%d %H:%M")
        st.rerun()

# í‚¤ì›Œë“œ ì¹© í‘œì‹œ
kws = st.session_state.keywords.get(selected_category, [])
if kws:
    st.write("Watching:")
    # í‚¤ì›Œë“œ ì‚­ì œ ë²„íŠ¼ ê·¸ë¦¬ë“œ
    cols = st.columns(8)
    for i, kw in enumerate(kws):
        if cols[i%8].button(f"{kw} âœ–", key=f"d_{kw}"):
            st.session_state.keywords[selected_category].remove(kw)
            save_keywords(st.session_state.keywords)
            st.rerun()
st.markdown('</div>', unsafe_allow_html=True)

# ==========================================
# 5. ê²°ê³¼ í‘œì‹œ (HTML ì˜¤ë¥˜ ìˆ˜ì • ì ìš©)
# ==========================================
data = st.session_state.news_data.get(selected_category, [])

if data:
    # ìš”ì•½ ì§€í‘œ
    m1, m2 = st.columns(2)
    m1.metric("Collected Articles", len(data))
    ai_count = sum(1 for d in data if d.get('AI_Verified'))
    m2.metric("AI Verified", ai_count)
    st.divider()

    # Grid Layout Loop
    # HTML ë¬¸ìì—´ ìƒì„± ì‹œ ë¶ˆí•„ìš”í•œ ê³µë°±ì„ ì—†ì• ê³  í•œ ì¤„ë¡œ ë§Œë“œëŠ” ê²ƒì´ í•µì‹¬
    for i in range(0, len(data), 2):
        row_items = data[i : i+2]
        cols = st.columns(2)
        
        for idx, item in enumerate(row_items):
            with cols[idx]:
                # 1. HTML Escape (ë‚´ìš©ì— ë”°ì˜´í‘œë‚˜ ê´„í˜¸ê°€ ìˆìœ¼ë©´ ê¹¨ì§ ë°©ì§€)
                safe_title = html.escape(item['Title'])
                safe_snip = html.escape(item.get('Snippet', ''))
                safe_src = html.escape(item['Source'])
                link = item['Link']
                date_str = item['Date'].strftime('%Y-%m-%d')
                
                # 2. ë±ƒì§€ HTML
                ai_badge = '<span style="background:#EEF2FF; color:#4F46E5; padding:2px 6px; border-radius:4px; font-size:0.7em; font-weight:bold; border:1px solid #C7D2FE; margin-left:5px;">âœ¨ AI Pick</span>' if item.get('AI_Verified') else ''
                
                # 3. HTML ì¡°ë¦½ (f-string ë“¤ì—¬ì“°ê¸° ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë¶™ì—¬ì”€)
                html_code = f"""
<div class="news-card-container">
    <div>
        <div class="card-header">
            <span class="card-source">{safe_src}</span>
            {ai_badge}
        </div>
        <a href="{link}" target="_blank" class="card-title">{safe_title}</a>
        <div class="card-snippet">{safe_snip}</div>
    </div>
    <div class="card-footer">
        <span>{date_str}</span>
        <span>#{item['Keyword']}</span>
    </div>
</div>
"""
                # 4. ë Œë”ë§ (unsafe_allow_html í•„ìˆ˜)
                st.markdown(html_code, unsafe_allow_html=True)

else:
    st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ì˜ 'ğŸš€ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
